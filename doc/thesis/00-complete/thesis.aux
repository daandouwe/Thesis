\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\new@tpo@label[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{dyer2016rnng,buys2015generative,buys2018exact}
\citation{dyer2016rnng}
\citation{buys2018exact}
\citation{dyer2016rnng}
\citation{stern2017minimal}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{7}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{01-introduction}{{1}{7}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline The approximate marginalization}{7}{section*.4}}
\citation{fu2006gradient}
\citation{williams1992reinforce}
\citation{rennie2017argmax}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Semi-supervised training by including unlabeled data}{8}{section*.5}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Alternative, simpler, models}{8}{section*.6}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Targeted syntactic evaluation}{8}{section*.7}}
\citation{huddleston2002grammar}
\citation{carnie2010constituent}
\citation{everaert2015structures}
\citation{huddleston2002grammar}
\citation{carnie2010constituent}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{9}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{02-background}{{2}{9}{Background}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Syntax}{9}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Constituents}{9}{subsection.2.1.1}}
\citation{carnie2010constituent}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:bird-tree}{{\caption@xref {fig:bird-tree}{ on input line 28}}{10}{Constituents}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Categories}{10}{subsection.2.1.2}}
\citation{everaert2015structures}
\citation{everaert2015structures}
\citation{everaert2015structures}
\citation{giannakidou2011npi}
\citation{everaert2015structures}
\citation{everaert2015structures}
\citation{everaert2015structures}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Hierarchy}{11}{subsection.2.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Hierarchical dependance of negative polarity items. Left shows the word \textit  {anybody} in the licensing context of \textit  {not}, while right shows the ungrammatical sentence where the word is not. Figure taken from \cite  {everaert2015structures}.\relax }}{11}{figure.caption.10}}
\newlabel{fig:trees-npi}{{2.1}{11}{Hierarchical dependance of negative polarity items. Left shows the word \textit {anybody} in the licensing context of \textit {not}, while right shows the ungrammatical sentence where the word is not. Figure taken from \cite {everaert2015structures}.\relax }{figure.caption.10}{}}
\newlabel{ref:trees-npi}{{(3)}{11}{Hierarchy}{figure.caption.10}{}}
\citation{tesniere1959elements,nivre2005dependency,hudson2010introduction}
\citation{frank2012hierarchical}
\citation{everaert2015structures}
\citation{hale2001earley,levy2008expectation,brennan2016abstract}
\citation{conway2008neurocognitive,gillespie2011hierarchy,christiansen2012similar,gillespie2013against,frank2012hierarchical}
\citation{marcus1993penn}
\citation{marcus1994annotating}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Controversy}{12}{subsection.2.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Parsing}{12}{section.2.2}}
\citation{andor2016globally}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Treebank}{13}{subsection.2.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Two representations of the tree in \ref  {fig:tree-cnf-spans}.\relax }}{13}{table.caption.12}}
\newlabel{tab:spans-rules}{{2.1}{13}{Two representations of the tree in \ref {fig:tree-cnf-spans}.\relax }{table.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Models}{13}{subsection.2.2.2}}
\citation{lafferty2001crf}
\citation{lafferty2001crf}
\citation{goldberg2013dynamic}
\citation{ballesteros2016exploration,stern2017minimal}
\citation{vlachos2012imitation,he2012imitation}
\citation{ballesteros2016exploration}
\citation{klein2018reinforce}
\citation{black1991parseval}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Metrics}{15}{subsection.2.2.3}}
\newlabel{eq:fscore}{{2.1}{15}{Metrics}{equation.2.2.1}{}}
\citation{sekine1997evalb}
\citation{chen1999empirical,kneser1995improved}
\citation{rosenfeld1996loglinear,bengio2003neural}
\citation{mikolov2010recurrent}
\citation{hochreiter1997long}
\citation{zaremba2014recurrent,jozefowicz2016exploring,melis2017state}
\citation{chelba2017n}
\citation{kalchbrenner2014convolutional}
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Language models}{16}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Models}{16}{subsection.2.3.1}}
\newlabel{eq:lm-factorized}{{2.2}{16}{Models}{equation.2.3.2}{}}
\citation{roark2001probabilistic}
\citation{chelba2000structured,emami2005neural}
\citation{pauls2012treelets}
\citation{chelba2013one}
\citation{merity2016pointer}
\citation{jelinek1997information}
\citation{chelba2017n}
\newlabel{eq:lm-latent}{{2.3}{17}{Models}{equation.2.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Data}{17}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Metrics}{17}{subsection.2.3.3}}
\citation{smith2012adversarial}
\citation{linzen2016syntax}
\citation{linzen2018targeted}
\citation{linzen2018targeted}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Neural networks}{18}{section.2.4}}
\citation{hochreiter1997long}
\newlabel{fig:tree-original}{{2.2a}{20}{Original Penn Treebank tree.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:tree-original}{{a}{20}{Original Penn Treebank tree.\relax }{figure.caption.11}{}}
\newlabel{fig:tree-simplified}{{2.2b}{20}{Function tags and traces removed.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:tree-simplified}{{b}{20}{Function tags and traces removed.\relax }{figure.caption.11}{}}
\newlabel{fig:tree-cnf}{{2.2c}{20}{Converted to normal form.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:tree-cnf}{{c}{20}{Converted to normal form.\relax }{figure.caption.11}{}}
\newlabel{fig:tree-cnf-spans}{{2.2d}{20}{In normal form with spans.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:tree-cnf-spans}{{d}{20}{In normal form with spans.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Converting a treebank tree (withouth part-of-speech tags).\relax }}{20}{figure.caption.11}}
\newlabel{fig:trees-ptb}{{2.2}{20}{Converting a treebank tree (withouth part-of-speech tags).\relax }{figure.caption.11}{}}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Recurrent Neural Network Grammars}{21}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{03-rnng}{{3}{21}{Recurrent Neural Network Grammars}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Model}{21}{section.3.1}}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Transition sytem}{22}{subsection.3.1.1}}
\newlabel{ex:disc-states}{{3.1.1}{22}{}{theorem.3.1.1}{}}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Model}{23}{subsection.3.1.2}}
\newlabel{eq:naive-rnng-model}{{3.1}{23}{Model}{equation.3.1.1}{}}
\citation{dyer2016rnng}
\citation{hale2018beam}
\newlabel{eq:action-regression}{{3.6}{25}{Model}{equation.3.1.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Parametrization}{26}{section.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Stack encoder}{26}{subsection.3.2.1}}
\citation{dyer2016rnng}
\citation{kuncoro2017syntax}
\citation{kuncoro2017syntax}
\citation{kuncoro2017syntax}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Composition function}{27}{subsection.3.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Training}{28}{section.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Inference}{28}{section.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Discriminative model}{28}{subsection.3.4.1}}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Generative model}{29}{subsection.3.4.2}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Approximate marginalization}{29}{section*.15}}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{gal2016theoretically}
\citation{neubig2017dynet}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Approximate MAP tree}{30}{section*.16}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Proposal distribution}{30}{section*.17}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Experiments}{30}{section.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Setup}{30}{subsection.3.5.1}}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{kuncoro2017syntax}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{kuncoro2017syntax}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{kuncoro2017syntax}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{kuncoro2017syntax}
\newlabel{sec:impl-embedding}{{3.5.1}{31}{Setup}{subsection.3.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Results}{31}{subsection.3.5.2}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces F1 scores for the discriminative RNNG.\relax }}{31}{table.caption.18}}
\newlabel{tab:disc-fscores}{{3.1}{31}{F1 scores for the discriminative RNNG.\relax }{table.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces F1 scores for the generative RNNG for different proposal models.\relax }}{31}{table.caption.19}}
\newlabel{tab:gen-fscores}{{3.2}{31}{F1 scores for the generative RNNG for different proposal models.\relax }{table.caption.19}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Perplexity of the generative RNNG for different proposal models.\relax }}{31}{table.caption.20}}
\newlabel{tab:gen-perplexities}{{3.3}{31}{Perplexity of the generative RNNG for different proposal models.\relax }{table.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Analysis}{32}{subsection.3.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces F1 estimated with increasing number of samples, with and without annealed distributions, for 10 independent repetitions. Horizontal lines show values of individual outcomes.\relax }}{33}{figure.caption.21}}
\newlabel{fig:samples-fscores}{{3.1}{33}{F1 estimated with increasing number of samples, with and without annealed distributions, for 10 independent repetitions. Horizontal lines show values of individual outcomes.\relax }{figure.caption.21}{}}
\citation{titov2007generative,buys2015bayesian,buys2015generative,buys2018exact}
\citation{roark2001probabilistic}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Perplexity estimated with increasing number of samples, with and without annealed distributions, for 10 independent repetitions. Horizontal lines show values of individual outcomes.\relax }}{34}{figure.caption.22}}
\newlabel{fig:samples-perplexities}{{3.2}{34}{Perplexity estimated with increasing number of samples, with and without annealed distributions, for 10 independent repetitions. Horizontal lines show values of individual outcomes.\relax }{figure.caption.22}{}}
\citation{kuncoro2017syntax}
\citation{linzen2016syntax,kuncoro2018learn}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Conditional entropy estimated with increasing number of samples, with and without annealed distributions, for 10 independent repetitions. Horizontal lines show values of individual outcomes.\relax }}{35}{figure.caption.23}}
\newlabel{fig:samples-entropy}{{3.3}{35}{Conditional entropy estimated with increasing number of samples, with and without annealed distributions, for 10 independent repetitions. Horizontal lines show values of individual outcomes.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Related work}{35}{section.3.6}}
\citation{brennan2016abstract}
\citation{hale2018beam}
\citation{stern2017beam}
\citation{stern2017minimal}
\citation{stern2017minimal}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Conditional Random Field parser}{37}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{04-crf}{{4}{37}{Conditional Random Field parser}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Model}{37}{section.4.1}}
\citation{finkel2008crf,klein2015crf}
\citation{stern2017minimal}
\citation{stern2017minimal}
\newlabel{eq:crf-model}{{4.1}{38}{Model}{equation.4.1.1}{}}
\citation{stern2017minimal}
\citation{dozat2016deep}
\citation{stern2018analyis}
\citation{stern2018analyis}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Representation for the span $(1, 4)$ computed from RNN encodings. Figure taken from \citet  {stern2018analyis}.\relax }}{39}{figure.caption.24}}
\newlabel{fig:span-feature}{{4.1}{39}{Representation for the span $(1, 4)$ computed from RNN encodings. Figure taken from \citet {stern2018analyis}.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Parametrization}{39}{section.4.2}}
\newlabel{eq:span-feature}{{4.3}{39}{Parametrization}{equation.4.2.3}{}}
\newlabel{eq:potential-function}{{4.4}{39}{Parametrization}{equation.4.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Inference}{39}{section.4.3}}
\newlabel{sect:inference}{{4.3}{39}{Inference}{section.4.3}{}}
\citation{baker1979trainable}
\citation{goodman1999semiring}
\citation{gallo1993directed,klein2004parsing}
\citation{goodman1999semiring,eisner2009semirings}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Weighted parse forest}{40}{subsection.4.3.1}}
\citation{goodman1999semiring}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces The edge-types making up the hypergraph. The edges are instatiated for all $A, B, C \in \Lambda $ and all $0 \leq i < j \leq n$. Only for the rightmost edge holds the restriction $A \not =\varnothing $, to ensure that the dummy label cannot be the top node.\relax }}{41}{figure.caption.25}}
\newlabel{fig:crf-edges}{{4.2}{41}{The edge-types making up the hypergraph. The edges are instatiated for all $A, B, C \in \Lambda $ and all $0 \leq i < j \leq n$. Only for the rightmost edge holds the restriction $A \neq \varnothing $, to ensure that the dummy label cannot be the top node.\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Inside recursion}{41}{subsection.4.3.2}}
\newlabel{eq:inside-base}{{4.5}{42}{Inside recursion}{equation.4.3.5}{}}
\newlabel{eq:inside}{{4.6}{42}{Inside recursion}{equation.4.3.6}{}}
\newlabel{eq:inside-simplified}{{4.7}{42}{Inside recursion}{equation.4.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Outside recursion}{43}{subsection.4.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Solutions}{44}{subsection.4.3.4}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Normalizer}{44}{section*.26}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Parse}{44}{section*.27}}
\newlabel{eq:viterbi-score}{{4.8}{44}{Parse}{equation.4.3.8}{}}
\newlabel{eq:viterbi-tree}{{4.10}{44}{Parse}{equation.4.3.10}{}}
\citation{goodman1999semiring}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Sample}{45}{section*.28}}
\newlabel{eq:sample}{{4.12}{45}{Sample}{equation.4.3.12}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Entropy}{45}{section*.29}}
\newlabel{eq:node-marginal}{{4.13}{45}{Entropy}{equation.4.3.13}{}}
\citation{eisner2009semirings}
\citation{eisner2016backprop}
\citation{kim2017structured}
\citation{neubig2017dynet}
\citation{stern2017minimal}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Traning}{46}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Objective}{46}{subsection.4.4.1}}
\citation{stern2017minimal}
\citation{stern2017minimal}
\citation{stern2017minimal}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Speed and complexity}{47}{subsection.4.4.2}}
\citation{stern2017minimal}
\citation{stern2017minimal}
\citation{stern2017minimal}
\citation{kingma2014adam}
\citation{stern2017minimal}
\citation{stern2017minimal}
\citation{stern2017minimal}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Experiments}{48}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Setup}{48}{subsection.4.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Results}{48}{subsection.4.5.2}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces F1 scores for the CRF.\relax }}{48}{table.caption.30}}
\newlabel{tab:disc-fscores}{{4.1}{48}{F1 scores for the CRF.\relax }{table.caption.30}{}}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{kuncoro2017syntax}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}Proposal distribution}{49}{subsection.4.5.3}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces F1 scores for the generative RNNG for different proposal models.\relax }}{49}{table.caption.31}}
\newlabel{tab:gen-fscores-crf}{{4.2}{49}{F1 scores for the generative RNNG for different proposal models.\relax }{table.caption.31}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Perplexity on the PTB of the generative RNNG, for different proposal models.\relax }}{49}{table.caption.32}}
\newlabel{tab:gen-perplexities-crf}{{4.3}{49}{Perplexity on the PTB of the generative RNNG, for different proposal models.\relax }{table.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}Analysis}{49}{subsection.4.5.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces F1 estimated with increasing number of samples, with CRF and discriminative RNNG annealed with $\alpha =0.8$, for 10 independent repetitions.\relax }}{50}{figure.caption.33}}
\newlabel{fig:samples-fscores}{{4.3}{50}{F1 estimated with increasing number of samples, with CRF and discriminative RNNG annealed with $\alpha =0.8$, for 10 independent repetitions.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Problems as proposal}{50}{section.4.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Derivational ambiguity}{50}{subsection.4.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Perplexity estimated with increasing number of samples, with CRF and discriminative RNNG annealed with $\alpha =0.8$, for 10 independent repetitions.\relax }}{51}{figure.caption.34}}
\newlabel{fig:samples-perplexities}{{4.4}{51}{Perplexity estimated with increasing number of samples, with CRF and discriminative RNNG annealed with $\alpha =0.8$, for 10 independent repetitions.\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Conditional entropy estimated with increasing number of samples.\relax }}{52}{figure.caption.35}}
\newlabel{fig:samples-entropy}{{4.5}{52}{Conditional entropy estimated with increasing number of samples.\relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Two normal form derivations that collapse to the same tree.\relax }}{53}{figure.caption.36}}
\newlabel{fig:normal-form-trees}{{4.6}{53}{Two normal form derivations that collapse to the same tree.\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Unrestricted parse forest}{53}{subsection.4.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Pruned parse forest}{55}{subsection.4.6.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Edges in the parse forest that produce the derivational ambiguity, whenever $k > i+1$.\relax }}{56}{figure.caption.37}}
\newlabel{fig:illegal-edges}{{4.7}{56}{Edges in the parse forest that produce the derivational ambiguity, whenever $k > i+1$.\relax }{figure.caption.37}{}}
\citation{finkel2008crf,klein2015crf}
\citation{stern2017minimal}
\citation{hall2014less}
\citation{finkel2008crf}
\citation{klein2015crf}
\citation{hall2014less}
\citation{stern2017minimal}
\citation{collins2003head}
\citation{klein2003accurate}
\citation{petrov2006learning}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Related work}{57}{section.4.7}}
\citation{klein2015crf}
\citation{linzen2018targeted}
\citation{enguehard2017multitask}
\citation{linzen2018targeted}
\citation{linzen2018targeted}
\citation{linzen2016syntax,gulordava2018colorless,linzen2018targeted}
\citation{linzen2016syntax}
\citation{tran2018recurrent}
\citation{kuncoro2018learn}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Syntactic evaluation}{59}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{06-syneval}{{5}{59}{Syntactic evaluation}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Syntactic evaluation}{59}{section.5.1}}
\citation{linzen2016syntax}
\citation{kuncoro2018learn}
\citation{everaert2015structures,xiang2009illusory}
\citation{linzen2016syntax}
\citation{gulordava2018colorless}
\citation{gulordava2018colorless}
\citation{warstadt2018acceptability}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Dataset}{60}{subsection.5.1.1}}
\citation{mccoy2018revisiting}
\citation{everaert2015structures}
\citation{chomsky1980rules}
\citation{zweig2011microsoft}
\citation{sennrich2017grammatical}
\citation{enguehard2017multitask,linzen2018targeted}
\citation{caruana1997multitask}
\citation{collobert2008unified,collobert2011natural,zhang2016multitask,goldberg2016multitask}
\citation{bangalore1999supertagging}
\citation{enguehard2017multitask}
\citation{swayamdipta2018scaffold}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Related work}{61}{subsection.5.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Multitask learning}{61}{section.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Multitask objective}{62}{subsection.5.2.1}}
\newlabel{eq:multitask-objective}{{5.1}{62}{Multitask objective}{equation.5.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Models}{62}{subsection.5.2.2}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Word labeling}{62}{section*.38}}
\citation{enguehard2017multitask}
\citation{linzen2018targeted}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Span labeling}{63}{section*.39}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Experiments}{63}{section.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Setup}{63}{subsection.5.3.1}}
\citation{linzen2018targeted}
\citation{linzen2018targeted}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Perplexity of the language models on the PTB test set.\relax }}{64}{table.caption.40}}
\newlabel{tab:gen-perplexities-crf}{{5.1}{64}{Perplexity of the language models on the PTB test set.\relax }{table.caption.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Results}{64}{subsection.5.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Syneval results for all categories.\relax }}{65}{figure.caption.41}}
\newlabel{fig:syneval-all}{{5.1}{65}{Syneval results for all categories.\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Syneval results for all categories.\relax }}{66}{figure.caption.42}}
\newlabel{fig:syneval-all-averaged}{{5.2}{66}{Syneval results for all categories.\relax }{figure.caption.42}{}}
\citation{jordan1999vi,blei2016vi}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Semisupervised learning}{67}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{05-semisupervised}{{6}{67}{Semisupervised learning}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Unsupervised learning}{67}{section.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Variational approximation}{67}{subsection.6.1.1}}
\citation{blei2016vi}
\citation{kingma2014vae}
\newlabel{eq:lowerbound}{{6.1}{68}{Variational approximation}{equation.6.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Approximate posterior}{68}{section.6.2}}
\citation{fu2006gradient}
\citation{williams1992reinforce,paisley2012viss,mnih2014nvil,ranganath2014black,miao2016discrete}
\citation{williams1992reinforce}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Training}{69}{section.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Gradients of joint parameters}{69}{subsection.6.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Gradients of posterior parameters}{69}{subsection.6.3.2}}
\citation{miao2016discrete}
\citation{rennie2017argmax}
\citation{miao2016discrete,yin2018structvae}
\citation{cheng2017rnng}
\citation{rennie2017argmax}
\citation{klein2018reinforce}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Variance reduction}{70}{section.6.4}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Experiments}{70}{section.6.5}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Related work}{70}{section.6.6}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusion}{71}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{07-conclusion}{{7}{71}{Conclusion}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Main contributions}{71}{section.7.1}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Global training of a chart based neural parser.}{71}{section*.43}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Semisupervised training of RNNGs.}{71}{section*.44}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Effective baselines for the score function estimator.}{71}{section*.45}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Future work}{71}{section.7.2}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Something.}{71}{section*.46}}
\citation{cross2016span}
\citation{stern2017minimal,kitaev2018attentive}
\citation{chelba2013one}
\citation{jozefowicz2016exploring}
\citation{merity2016pointer}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Implementation}{72}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{A2-implementation}{{A}{72}{Implementation}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Data}{72}{section.A.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Datasets}{72}{subsection.A.1.1}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Penn Treebank}{72}{section*.47}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline One Billion Word Benchmark}{72}{section*.48}}
\citation{hockenmaier2007ccgbank}
\citation{enguehard2017multitask}
\citation{linzen2018targeted}
\citation{stern2017minimal}
\citation{dyer2016rnng}
\citation{petrov2006learning}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline CCG supertags}{73}{section*.49}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.2}Vocabularies}{73}{subsection.A.1.2}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Unknown words}{73}{section*.50}}
\citation{glorot2010understanding}
\citation{peters2018elmo}
\citation{kitaev2018attentive}
\citation{stern2017minimal}
\citation{stern2017minimal}
\citation{stern2018analyis}
\citation{neubig2017dynet}
\citation{neubig2017fly}
\citation{neubig2017dynet,baydin2018automatic}
\citation{wilson2017marginal}
\citation{dyer2016rnng}
\citation{kingma2014adam}
\citation{kingma2014adam}
\citation{ranganath2014black,klein2018reinforce}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Vocabularies\relax }}{74}{table.caption.52}}
\newlabel{tab:vocabularies}{{A.1}{74}{Vocabularies\relax }{table.caption.52}{}}
\newlabel{sec:impl-embedding}{{A.1.2}{74}{Embeddings}{section*.51}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Embeddings}{74}{section*.51}}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Number of parameters in models used.\relax }}{74}{table.caption.53}}
\newlabel{tab:num-params}{{A.2}{74}{Number of parameters in models used.\relax }{table.caption.53}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Implementation}{74}{section.A.2}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Optimization}{74}{section*.54}}
\citation{schulman2015gradient}
\citation{gallo1993directed,klein2004parsing}
\citation{goodman1999semiring,eisner2009semirings}
\citation{klein2004parsing}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Semiring parsing}{76}{appendix.B}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{A3-crf}{{B}{76}{Semiring parsing}{appendix.B}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Hypergraph}{76}{section.B.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.1}{\ignorespaces A fraction of a parse hypergraph showing two possible parses.\relax }}{77}{figure.caption.55}}
\newlabel{fig:hypergraph}{{B.1}{77}{A fraction of a parse hypergraph showing two possible parses.\relax }{figure.caption.55}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.2}Semiring}{77}{section.B.2}}
\citation{goodman1999semiring}
\citation{goodman1999semiring}
\@writefile{toc}{\contentsline {section}{\numberline {B.3}Semiring parsing}{78}{section.B.3}}
\citation{eisner2009semirings}
\citation{goodman1999semiring}
\citation{baker1979trainable}
\newlabel{eq:derivation-weight}{{B.3}{79}{}{equation.B.3.3}{}}
\newlabel{eq:hypergraph-weight}{{B.4}{79}{}{equation.B.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3.1}Inside and outside recursions}{79}{subsection.B.3.1}}
\citation{goodman1999semiring}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3.2}Instantiated recursions}{80}{subsection.B.3.2}}
\newlabel{ex:vit-weight}{{B.3.7}{80}{}{theorem.B.3.7}{}}
\newlabel{ex:vit-derivation}{{B.3.8}{80}{}{theorem.B.3.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {C}Score function estimator}{82}{appendix.C}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{A4-vi}{{C}{82}{Score function estimator}{appendix.C}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C.1}Derivation}{82}{section.C.1}}
\newlabel{eq:score-function-estimator}{{C.1}{82}{Derivation}{equation.C.1.1}{}}
\citation{baydin2017automatic}
\citation{schulman2015gradient}
\citation{paisley2012viss}
\citation{ross2006simulation}
\@writefile{toc}{\contentsline {section}{\numberline {C.2}Optimization}{83}{section.C.2}}
\newlabel{eq:surrogate}{{C.2}{83}{Optimization}{equation.C.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C.3}Variance reduction}{83}{section.C.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3.1}Variance}{84}{subsection.C.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3.2}Control variates}{84}{subsection.C.3.2}}
\citation{ross2006simulation}
\newlabel{eq:cv-scale}{{C.3}{85}{Control variates}{equation.C.3.3}{}}
\newlabel{eq:var-red}{{C.4}{85}{Control variates}{equation.C.3.4}{}}
\citation{linzen2018targeted}
\citation{linzen2018targeted}
\@writefile{toc}{\contentsline {chapter}{\numberline {D}Syneval dataset}{87}{appendix.D}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{A5-syneval}{{D}{87}{Syneval dataset}{appendix.D}{}}
\bibstyle{plainnat}
\bibdata{../src/bibliography.bib}
\bibcite{andor2016globally}{{1}{2016}{{Andor et~al.}}{{Andor, Alberti, Weiss, Severyn, Presta, Ganchev, Petrov, and Collins}}}
\bibcite{baker1979trainable}{{2}{1979}{{Baker}}{{}}}
\bibcite{ballesteros2016exploration}{{3}{2016}{{Ballesteros et~al.}}{{Ballesteros, Goldberg, Dyer, and Smith}}}
\bibcite{bangalore1999supertagging}{{4}{1999}{{Bangalore and Joshi}}{{}}}
\bibcite{baydin2018automatic}{{5}{2018}{{Baydin et~al.}}{{Baydin, Pearlmutter, Radul, and Siskind}}}
\bibcite{bengio2003neural}{{6}{2003}{{Bengio et~al.}}{{Bengio, Ducharme, Vincent, and Jauvin}}}
\bibcite{black1991parseval}{{7}{1991}{{Black et~al.}}{{Black, Abney, Flickenger, Gdaniec, Grishman, Harrison, Hindle, Ingria, Jelinek, Klavans, et~al.}}}
\bibcite{blei2016vi}{{8}{2016}{{Blei et~al.}}{{Blei, Kucukelbir, and McAuliffe}}}
\bibcite{brennan2016abstract}{{9}{2016}{{Brennan et~al.}}{{Brennan, Stabler, Van~Wagenen, Luh, and Hale}}}
\bibcite{buys2015bayesian}{{10}{2015{a}}{{Buys and Blunsom}}{{}}}
\bibcite{buys2015generative}{{11}{2015{b}}{{Buys and Blunsom}}{{}}}
\bibcite{buys2018exact}{{12}{2018}{{Buys and Blunsom}}{{}}}
\bibcite{carnie2010constituent}{{13}{2010}{{Carnie}}{{}}}
\bibcite{caruana1997multitask}{{14}{1997}{{Caruana}}{{}}}
\bibcite{chelba2000structured}{{15}{2000}{{Chelba and Jelinek}}{{}}}
\bibcite{chelba2013one}{{16}{2013}{{Chelba et~al.}}{{Chelba, Mikolov, Schuster, Ge, Brants, Koehn, and Robinson}}}
\bibcite{chelba2017n}{{17}{2017}{{Chelba et~al.}}{{Chelba, Norouzi, and Bengio}}}
\bibcite{chen1999empirical}{{18}{1999}{{Chen and Goodman}}{{}}}
\bibcite{cheng2017rnng}{{19}{2017}{{Cheng et~al.}}{{Cheng, Lopez, and Lapata}}}
\bibcite{chomsky1980rules}{{20}{1980}{{Chomsky}}{{}}}
\bibcite{christiansen2012similar}{{21}{2012}{{Christiansen et~al.}}{{Christiansen, Conway, and Onnis}}}
\bibcite{collins2003head}{{22}{2003}{{Collins}}{{}}}
\bibcite{collobert2008unified}{{23}{2008}{{Collobert and Weston}}{{}}}
\bibcite{collobert2011natural}{{24}{2011}{{Collobert et~al.}}{{Collobert, Weston, Bottou, Karlen, Kavukcuoglu, and Kuksa}}}
\bibcite{conway2008neurocognitive}{{25}{2008}{{Conway and Pisoni}}{{}}}
\bibcite{cross2016span}{{26}{2016}{{Cross and Huang}}{{}}}
\bibcite{dozat2016deep}{{27}{2016}{{Dozat and Manning}}{{}}}
\bibcite{klein2015crf}{{28}{2015}{{Durrett and Klein}}{{}}}
\bibcite{dyer2016rnng}{{29}{2016}{{Dyer et~al.}}{{Dyer, Kuncoro, Ballesteros, and Smith}}}
\bibcite{eisner2016backprop}{{30}{2016}{{Eisner}}{{}}}
\bibcite{emami2005neural}{{31}{2005}{{Emami and Jelinek}}{{}}}
\bibcite{enguehard2017multitask}{{32}{2017}{{Enguehard et~al.}}{{Enguehard, Goldberg, and Linzen}}}
\bibcite{everaert2015structures}{{33}{2015}{{Everaert et~al.}}{{Everaert, Huybregts, Chomsky, Berwick, and Bolhuis}}}
\bibcite{finkel2008crf}{{34}{2008}{{Finkel et~al.}}{{Finkel, Kleeman, and Manning}}}
\bibcite{frank2012hierarchical}{{35}{2012}{{Frank et~al.}}{{Frank, Bod, and Christiansen}}}
\bibcite{klein2018reinforce}{{36}{2018}{{Fried and Klein}}{{}}}
\bibcite{fu2006gradient}{{37}{2006}{{Fu}}{{}}}
\bibcite{stern2018analyis}{{38}{2018}{{Gaddy et~al.}}{{Gaddy, Stern, and Klein}}}
\bibcite{gal2016theoretically}{{39}{2016}{{Gal and Ghahramani}}{{}}}
\bibcite{gallo1993directed}{{40}{1993}{{Gallo et~al.}}{{Gallo, Longo, Pallottino, and Nguyen}}}
\bibcite{giannakidou2011npi}{{41}{2011}{{Giannakidou}}{{}}}
\bibcite{gillespie2011hierarchy}{{42}{2011}{{Gillespie and Pearlmutter}}{{}}}
\bibcite{gillespie2013against}{{43}{2013}{{Gillespie and Pearlmutter}}{{}}}
\bibcite{glorot2010understanding}{{44}{2010}{{Glorot and Bengio}}{{}}}
\bibcite{goldberg2013dynamic}{{45}{2013}{{Goldberg and Nivre}}{{}}}
\bibcite{goodman1999semiring}{{46}{1999}{{Goodman}}{{}}}
\bibcite{gulordava2018colorless}{{47}{2018}{{Gulordava et~al.}}{{Gulordava, Bojanowski, Grave, Linzen, and Baroni}}}
\bibcite{hale2001earley}{{48}{2001}{{Hale}}{{}}}
\bibcite{hale2018beam}{{49}{2018}{{Hale et~al.}}{{Hale, Dyer, Kuncoro, and Brennan}}}
\bibcite{hall2014less}{{50}{2014}{{Hall et~al.}}{{Hall, Durrett, and Klein}}}
\bibcite{he2012imitation}{{51}{2012}{{He et~al.}}{{He, Eisner, and Daume}}}
\bibcite{hochreiter1997long}{{52}{1997}{{Hochreiter and Schmidhuber}}{{}}}
\bibcite{hockenmaier2007ccgbank}{{53}{2007}{{Hockenmaier and Steedman}}{{}}}
\bibcite{huddleston2002grammar}{{54}{2002}{{Huddleston and Pullum}}{{}}}
\bibcite{hudson2010introduction}{{55}{2010}{{Hudson}}{{}}}
\bibcite{jelinek1997information}{{56}{1997}{{Jelinek}}{{}}}
\bibcite{jordan1999vi}{{57}{1999}{{Jordan et~al.}}{{Jordan, Ghahramani, Jaakkola, and Saul}}}
\bibcite{jozefowicz2016exploring}{{58}{2016}{{Jozefowicz et~al.}}{{Jozefowicz, Vinyals, Schuster, Shazeer, and Wu}}}
\bibcite{kalchbrenner2014convolutional}{{59}{2014}{{Kalchbrenner et~al.}}{{Kalchbrenner, Grefenstette, and Blunsom}}}
\bibcite{kim2017structured}{{60}{2017}{{Kim et~al.}}{{Kim, Denton, Hoang, and Rush}}}
\bibcite{kingma2014adam}{{61}{2014}{{Kingma and Ba}}{{}}}
\bibcite{kingma2014vae}{{62}{2014}{{Kingma and Welling}}{{}}}
\bibcite{kitaev2018attentive}{{63}{2018}{{Kitaev and Klein}}{{}}}
\bibcite{klein2003accurate}{{64}{2003}{{Klein and Manning}}{{}}}
\bibcite{klein2004parsing}{{65}{2004}{{Klein and Manning}}{{}}}
\bibcite{kneser1995improved}{{66}{1995}{{Kneser and Ney}}{{}}}
\bibcite{kuncoro2017syntax}{{67}{2017}{{Kuncoro et~al.}}{{Kuncoro, Ballesteros, Kong, Dyer, Neubig, and Smith}}}
\bibcite{kuncoro2018learn}{{68}{2018}{{Kuncoro et~al.}}{{Kuncoro, Dyer, Hale, Yogatama, Clark, and Blunsom}}}
\bibcite{lafferty2001crf}{{69}{2001}{{Lafferty et~al.}}{{Lafferty, McCallum, and Pereira}}}
\bibcite{levy2008expectation}{{70}{2008}{{Levy}}{{}}}
\bibcite{eisner2009semirings}{{71}{2009}{{Li and Eisner}}{{}}}
\bibcite{linzen2016syntax}{{72}{2016}{{Linzen et~al.}}{{Linzen, Dupoux, and Goldberg}}}
\bibcite{marcus1994annotating}{{73}{1994}{{Marcus et~al.}}{{Marcus, Kim, Marcinkiewicz, MacIntyre, Bies, Ferguson, Katz, and Schasberger}}}
\bibcite{marcus1993penn}{{74}{1993}{{Marcus et~al.}}{{Marcus, Marcinkiewicz, and Santorini}}}
\bibcite{linzen2018targeted}{{75}{2018}{{Marvin and Linzen}}{{}}}
\bibcite{mccoy2018revisiting}{{76}{2018}{{McCoy et~al.}}{{McCoy, Linzen, and Frank}}}
\bibcite{melis2017state}{{77}{2017}{{Melis et~al.}}{{Melis, Dyer, and Blunsom}}}
\bibcite{merity2016pointer}{{78}{2016}{{Merity et~al.}}{{Merity, Xiong, Bradbury, and Socher}}}
\bibcite{miao2016discrete}{{79}{2016}{{Miao and Blunsom}}{{}}}
\bibcite{mikolov2010recurrent}{{80}{2010}{{Mikolov et~al.}}{{Mikolov, Karafi{\'a}t, Burget, {\v {C}}ernock{\`y}, and Khudanpur}}}
\bibcite{mnih2014nvil}{{81}{2014}{{Mnih and Gregor}}{{}}}
\bibcite{neubig2017dynet}{{82}{2017{a}}{{Neubig et~al.}}{{Neubig, Dyer, Goldberg, Matthews, Ammar, Anastasopoulos, Ballesteros, Chiang, Clothiaux, Cohn, et~al.}}}
\bibcite{neubig2017fly}{{83}{2017{b}}{{Neubig et~al.}}{{Neubig, Goldberg, and Dyer}}}
\bibcite{nivre2005dependency}{{84}{2005}{{Nivre}}{{}}}
\bibcite{paisley2012viss}{{85}{2012}{{Paisley et~al.}}{{Paisley, Blei, and Jordan}}}
\bibcite{pauls2012treelets}{{86}{2012}{{Pauls and Klein}}{{}}}
\bibcite{peters2018elmo}{{87}{2018}{{Peters et~al.}}{{Peters, Neumann, Iyyer, Gardner, Clark, Lee, and Zettlemoyer}}}
\bibcite{petrov2006learning}{{88}{2006}{{Petrov et~al.}}{{Petrov, Barrett, Thibaux, and Klein}}}
\bibcite{ranganath2014black}{{89}{2014}{{Ranganath et~al.}}{{Ranganath, Gerrish, and Blei}}}
\bibcite{rennie2017argmax}{{90}{2017}{{Rennie et~al.}}{{Rennie, Marcheret, Mroueh, Ross, and Goel}}}
\bibcite{roark2001probabilistic}{{91}{2001}{{Roark}}{{}}}
\bibcite{rosenfeld1996loglinear}{{92}{1996}{{Rosenfeld}}{{}}}
\bibcite{ross2006simulation}{{93}{2006}{{Ross}}{{}}}
\bibcite{schulman2015gradient}{{94}{2015}{{Schulman et~al.}}{{Schulman, Heess, Weber, and Abbeel}}}
\bibcite{sekine1997evalb}{{95}{1997}{{Sekine and Collins}}{{}}}
\bibcite{sennrich2017grammatical}{{96}{2017}{{Sennrich}}{{}}}
\bibcite{smith2012adversarial}{{97}{2012}{{Smith}}{{}}}
\bibcite{goldberg2016multitask}{{98}{2016}{{S{\o }gaard and Goldberg}}{{}}}
\bibcite{stern2017minimal}{{99}{2017{a}}{{Stern et~al.}}{{Stern, Andreas, and Klein}}}
\bibcite{stern2017beam}{{100}{2017{b}}{{Stern et~al.}}{{Stern, Fried, and Klein}}}
\bibcite{swayamdipta2018scaffold}{{101}{2018}{{Swayamdipta et~al.}}{{Swayamdipta, Thomson, Lee, Zettlemoyer, Dyer, and Smith}}}
\bibcite{tesniere1959elements}{{102}{1959}{{Tesni{\`e}re}}{{}}}
\bibcite{titov2007generative}{{103}{2007}{{Titov and Henderson}}{{}}}
\bibcite{tran2018recurrent}{{104}{2018}{{Tran et~al.}}{{Tran, Bisazza, and Monz}}}
\bibcite{vaswani2017attention}{{105}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{vlachos2012imitation}{{106}{2013}{{Vlachos}}{{}}}
\bibcite{warstadt2018acceptability}{{107}{2018}{{Warstadt et~al.}}{{Warstadt, Singh, and Bowman}}}
\bibcite{williams1992reinforce}{{108}{1992}{{Williams}}{{}}}
\bibcite{wilson2017marginal}{{109}{2017}{{Wilson et~al.}}{{Wilson, Roelofs, Stern, Srebro, and Recht}}}
\bibcite{xiang2009illusory}{{110}{2009}{{Xiang et~al.}}{{Xiang, Dillon, and Phillips}}}
\bibcite{yin2018structvae}{{111}{2018}{{Yin et~al.}}{{Yin, Zhou, He, and Neubig}}}
\bibcite{zaremba2014recurrent}{{112}{2014}{{Zaremba et~al.}}{{Zaremba, Sutskever, and Vinyals}}}
\bibcite{zhang2016multitask}{{113}{2016}{{Zhang and Weiss}}{{}}}
\bibcite{zweig2011microsoft}{{114}{2011}{{Zweig and Burges}}{{}}}
\global\csname @altsecnumformattrue\endcsname
\global\@namedef{scr@dte@chapter@lastmaxnumwidth}{16.23872pt}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{23.84888pt}
\global\@namedef{scr@dte@subsection@lastmaxnumwidth}{32.06136pt}
