\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\new@tpo@label[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{dyer2016rnng,buys2015generative,buys2018exact}
\citation{dyer2016rnng}
\citation{buys2018exact}
\citation{dyer2016rnng}
\citation{stern2017minimal}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{7}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{01-introduction}{{1}{7}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline The approximate marginalization}{7}{section*.4}}
\citation{fu2006gradient}
\citation{williams1992reinforce}
\citation{rennie2017argmax}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Semi-supervised training by including unlabeled data}{8}{section*.5}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Alternative, simpler, models}{8}{section*.6}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Targeted syntactic evaluation}{8}{section*.7}}
\citation{huddleston2002grammar}
\citation{carnie2010constituent}
\citation{everaert2015structures}
\citation{huddleston2002grammar}
\citation{carnie2010constituent}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{9}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{02-background}{{2}{9}{Background}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Syntax}{9}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Constituents}{9}{subsection.2.1.1}}
\citation{carnie2010constituent}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:bird-tree}{{\caption@xref {fig:bird-tree}{ on input line 28}}{10}{Constituents}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Categories}{10}{subsection.2.1.2}}
\citation{everaert2015structures}
\citation{everaert2015structures}
\citation{everaert2015structures}
\citation{giannakidou2011npi}
\citation{everaert2015structures}
\citation{everaert2015structures}
\citation{everaert2015structures}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Hierarchy}{11}{subsection.2.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Hierarchical dependance of negative polarity items. Left shows the word \textit  {anybody} in the licensing context of \textit  {not}, while right shows the ungrammatical sentence where the word is not. Figure taken without permission from \cite  {everaert2015structures}.\relax }}{11}{figure.caption.10}}
\newlabel{fig:trees-npi}{{2.1}{11}{Hierarchical dependance of negative polarity items. Left shows the word \textit {anybody} in the licensing context of \textit {not}, while right shows the ungrammatical sentence where the word is not. Figure taken without permission from \cite {everaert2015structures}.\relax }{figure.caption.10}{}}
\newlabel{ref:trees-npi}{{(3)}{11}{Hierarchy}{figure.caption.10}{}}
\citation{tesniere1959elements,nivre2005dependency,hudson2010introduction}
\citation{frank2012hierarchical}
\citation{everaert2015structures}
\citation{hale2001earley,levy2008expectation,brennan2016abstract}
\citation{conway2008neurocognitive,gillespie2011hierarchy,christiansen2012similar,gillespie2013against,frank2012hierarchical}
\citation{marcus1993penn}
\citation{marcus1994annotating}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Controversy}{12}{subsection.2.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Parsing}{12}{section.2.2}}
\citation{andor2016globally}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Treebank}{13}{subsection.2.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Two representations of the tree in \ref  {fig:tree-cnf-spans}.\relax }}{13}{table.caption.12}}
\newlabel{tab:spans-rules}{{2.1}{13}{Two representations of the tree in \ref {fig:tree-cnf-spans}.\relax }{table.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Models}{13}{subsection.2.2.2}}
\citation{lafferty2001crf}
\citation{lafferty2001crf}
\citation{goldberg2013dynamic}
\citation{ballesteros2016exploration,stern2017minimal}
\citation{vlachos2012imitation,he2012imitation}
\citation{ballesteros2016exploration}
\citation{klein2018reinforce}
\citation{black1991parseval}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Metrics}{15}{subsection.2.2.3}}
\newlabel{eq:fscore}{{2.1}{15}{Metrics}{equation.2.2.1}{}}
\citation{sekine1997evalb}
\citation{chen1999empirical,kneser1995improved}
\citation{rosenfeld1996loglinear,bengio2003neural}
\citation{mikolov2010recurrent}
\citation{hochreiter1997long}
\citation{zaremba2014recurrent,jozefowicz2016exploring,melis2017state}
\citation{chelba2017n}
\citation{kalchbrenner2014convolutional}
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Language models}{16}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Models}{16}{subsection.2.3.1}}
\newlabel{eq:lm-factorized}{{2.2}{16}{Models}{equation.2.3.2}{}}
\citation{roark2001probabilistic}
\citation{chelba2000structured,emami2005neural}
\citation{pauls2012treelets}
\citation{chelba2013one}
\citation{merity2016pointer}
\citation{jelinek1997information}
\citation{chelba2017n}
\newlabel{eq:lm-latent}{{2.3}{17}{Models}{equation.2.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Data}{17}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Metrics}{17}{subsection.2.3.3}}
\citation{smith2012adversarial}
\citation{linzen2016syntax}
\citation{linzen2018targeted}
\citation{linzen2018targeted}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Neural networks}{18}{section.2.4}}
\citation{hochreiter1997long}
\newlabel{fig:tree-original}{{2.2a}{20}{Original Penn Treebank tree.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:tree-original}{{a}{20}{Original Penn Treebank tree.\relax }{figure.caption.11}{}}
\newlabel{fig:tree-simplified}{{2.2b}{20}{Function tags and traces removed.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:tree-simplified}{{b}{20}{Function tags and traces removed.\relax }{figure.caption.11}{}}
\newlabel{fig:tree-cnf}{{2.2c}{20}{Converted to normal form.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:tree-cnf}{{c}{20}{Converted to normal form.\relax }{figure.caption.11}{}}
\newlabel{fig:tree-cnf-spans}{{2.2d}{20}{In normal form with spans.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:tree-cnf-spans}{{d}{20}{In normal form with spans.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Converting a treebank tree (withouth part-of-speech tags).\relax }}{20}{figure.caption.11}}
\newlabel{fig:trees-ptb}{{2.2}{20}{Converting a treebank tree (withouth part-of-speech tags).\relax }{figure.caption.11}{}}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Recurrent Neural Network Grammars}{21}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{03-rnng}{{3}{21}{Recurrent Neural Network Grammars}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Model}{21}{section.3.1}}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Transition sytem}{22}{subsection.3.1.1}}
\newlabel{ex:disc-states}{{3.1.1}{22}{}{theorem.3.1.1}{}}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Model}{23}{subsection.3.1.2}}
\newlabel{eq:naive-rnng-model}{{3.1}{23}{Model}{equation.3.1.1}{}}
\citation{dyer2016rnng}
\citation{hale2018beam}
\newlabel{eq:action-regression}{{3.6}{25}{Model}{equation.3.1.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Parametrization}{25}{section.3.2}}
\citation{dyer2016rnng}
\citation{kuncoro2017syntax}
\citation{kuncoro2017syntax}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Stack encoder}{26}{subsection.3.2.1}}
\citation{kuncoro2017syntax}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Composition function}{27}{subsection.3.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Training}{28}{section.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Inference}{28}{section.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Discriminative model}{28}{subsection.3.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Generative model}{28}{subsection.3.4.2}}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Approximate marginalization}{29}{section*.15}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Approximate MAP tree}{29}{section*.16}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Proposal distribution}{29}{section*.17}}
\citation{dyer2016rnng}
\citation{gal2016theoretically}
\citation{neubig2017dynet}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{kuncoro2017syntax}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{kuncoro2017syntax}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Experiments}{30}{section.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Models}{30}{subsection.3.5.1}}
\newlabel{sec:impl-embedding}{{3.5.1}{30}{Models}{subsection.3.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Results}{30}{subsection.3.5.2}}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{kuncoro2017syntax}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{kuncoro2017syntax}
\citation{titov2007generative,buys2015bayesian,buys2015generative,buys2018exact}
\citation{roark2001probabilistic}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces F1 scores for the discriminative RNNG.\relax }}{31}{table.caption.18}}
\newlabel{tab:disc-fscores}{{3.1}{31}{F1 scores for the discriminative RNNG.\relax }{table.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces F1 scores for the generative RNNG for different proposal models.\relax }}{31}{table.caption.19}}
\newlabel{tab:gen-fscores}{{3.2}{31}{F1 scores for the generative RNNG for different proposal models.\relax }{table.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Samples}{31}{subsection.3.5.3}}
\citation{kuncoro2017syntax}
\citation{linzen2016syntax,kuncoro2018learn}
\citation{brennan2016abstract}
\citation{hale2018beam}
\citation{stern2017beam}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Perplexity of the generative RNNG for different proposal models.\relax }}{32}{table.caption.20}}
\newlabel{tab:gen-perplexities}{{3.3}{32}{Perplexity of the generative RNNG for different proposal models.\relax }{table.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces F1 for varying number of samples, with and without annealed distributions, for 10 independent repetitions. Horizontal lines show values of individual outcomes.\relax }}{32}{figure.caption.21}}
\newlabel{fig:samples-fscores}{{3.1}{32}{F1 for varying number of samples, with and without annealed distributions, for 10 independent repetitions. Horizontal lines show values of individual outcomes.\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Related work}{32}{section.3.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Perplexity for varying number of samples, with and without annealed distributions, for 10 independent repetitions. Horizontal lines show values of individual outcomes.\relax }}{33}{figure.caption.22}}
\newlabel{fig:samples-perplexities}{{3.2}{33}{Perplexity for varying number of samples, with and without annealed distributions, for 10 independent repetitions. Horizontal lines show values of individual outcomes.\relax }{figure.caption.22}{}}
\citation{stern2017minimal}
\citation{stern2017minimal}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Conditional Random Field parser}{34}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{04-crf}{{4}{34}{Conditional Random Field parser}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Model}{34}{section.4.1}}
\citation{finkel2008crf,klein2015crf}
\citation{stern2017minimal}
\citation{stern2017minimal}
\newlabel{eq:crf-model}{{4.1}{35}{Model}{equation.4.1.1}{}}
\citation{stern2017minimal}
\citation{dozat2016deep}
\citation{stern2018analyis}
\citation{stern2018analyis}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Representation for the span $(1, 4)$ computed from $\textsc  {Rnn}$ encodings. Taken from \citet  {stern2018analyis}.\relax }}{36}{figure.caption.23}}
\newlabel{fig:span-feature}{{4.1}{36}{Representation for the span $(1, 4)$ computed from $\rnn $ encodings. Taken from \citet {stern2018analyis}.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Parametrization}{36}{section.4.2}}
\newlabel{eq:span-feature}{{4.3}{36}{Parametrization}{equation.4.2.3}{}}
\newlabel{eq:potential-function}{{4.4}{36}{Parametrization}{equation.4.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Inference}{36}{section.4.3}}
\newlabel{sect:inference}{{4.3}{36}{Inference}{section.4.3}{}}
\citation{baker1979trainable}
\citation{goodman1999semiring}
\citation{gallo1993directed,klein2004parsing}
\citation{goodman1999semiring,eisner2009semirings}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Weighted parse forest}{37}{subsection.4.3.1}}
\citation{goodman1999semiring}
\newlabel{fig:crf-edges}{{\caption@xref {fig:crf-edges}{ on input line 85}}{38}{Weighted parse forest}{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces The edge-types making up the hypergraph. The edges are instatiated for all $A, B, C \in \Lambda $ and all $0 \leq i < j \leq n$. Only for the rightmost edge holds the restriction $A \not =\varnothing $, to ensure that the dummy label cannot be the top node.\relax }}{38}{figure.caption.24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Inside recursion}{38}{subsection.4.3.2}}
\newlabel{eq:inside-base}{{4.5}{39}{Inside recursion}{equation.4.3.5}{}}
\newlabel{eq:inside}{{4.6}{39}{Inside recursion}{equation.4.3.6}{}}
\newlabel{eq:inside-simplified}{{4.7}{39}{Inside recursion}{equation.4.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Outside recursion}{40}{subsection.4.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Solutions}{41}{subsection.4.3.4}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Normalizer}{41}{section*.25}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Parse}{41}{section*.26}}
\newlabel{eq:viterbi-score}{{4.8}{41}{Parse}{equation.4.3.8}{}}
\newlabel{eq:viterbi-tree}{{4.10}{41}{Parse}{equation.4.3.10}{}}
\citation{goodman1999semiring}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Sample}{42}{section*.27}}
\newlabel{eq:sample}{{4.12}{42}{Sample}{equation.4.3.12}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Entropy}{42}{section*.28}}
\newlabel{eq:node-marginal}{{4.13}{42}{Entropy}{equation.4.3.13}{}}
\citation{eisner2009semirings}
\citation{eisner2016backprop}
\citation{kim2017structured}
\citation{stern2017minimal}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Traning}{43}{section.4.4}}
\citation{stern2017minimal}
\citation{stern2017minimal}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Experiments}{44}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Supervised model}{44}{subsection.4.5.1}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces F1 scores for the CRF.\relax }}{44}{table.caption.29}}
\newlabel{tab:disc-fscores}{{4.1}{44}{F1 scores for the CRF.\relax }{table.caption.29}{}}
\citation{buys2018exact}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Proposal model}{45}{subsection.4.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}Sampler}{45}{subsection.4.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Problems as proposal}{46}{section.4.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Two normal form derivations that collapse to the same tree.\relax }}{46}{figure.caption.30}}
\newlabel{fig:normal-form-trees}{{4.3}{46}{Two normal form derivations that collapse to the same tree.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Unrestricted parse forest}{47}{subsection.4.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Pruned parse forest}{48}{subsection.4.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Edges in the parse forest that produce the derivational ambiguity, whenever $k > i+1$.\relax }}{49}{figure.caption.31}}
\newlabel{fig:illegal-edges}{{4.4}{49}{Edges in the parse forest that produce the derivational ambiguity, whenever $k > i+1$.\relax }{figure.caption.31}{}}
\citation{finkel2008crf,klein2015crf}
\citation{stern2017minimal}
\citation{hall2014less}
\citation{finkel2008crf}
\citation{klein2015crf}
\citation{stern2017minimal}
\citation{collins2003head}
\citation{klein2003accurate}
\citation{petrov2006learning}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Related work}{50}{section.4.7}}
\citation{klein2015crf}
\citation{linzen2018targeted}
\citation{enguehard2017multitask}
\citation{linzen2018targeted}
\citation{linzen2018targeted}
\citation{linzen2016syntax,gulordava2018colorless,linzen2018targeted}
\citation{linzen2016syntax}
\citation{tran2018recurrent}
\citation{kuncoro2018learn}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Syntactic evaluation}{52}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{06-syneval}{{5}{52}{Syntactic evaluation}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Syntactic evaluation}{52}{section.5.1}}
\citation{linzen2016syntax}
\citation{kuncoro2018learn}
\citation{everaert2015structures,xiang2009illusory}
\citation{linzen2016syntax}
\citation{gulordava2018colorless}
\citation{gulordava2018colorless}
\citation{warstadt2018acceptability}
\citation{mccoy2018revisiting}
\citation{everaert2015structures}
\citation{chomsky1980rules}
\citation{zweig2011microsoft}
\citation{sennrich2017grammatical}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Dataset}{53}{section*.32}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Categories}{53}{section*.33}}
\citation{enguehard2017multitask,linzen2018targeted}
\citation{caruana1997multitask}
\citation{collobert2008unified,collobert2011natural,zhang2016multitask,goldberg2016multitask}
\citation{bangalore1999supertagging}
\citation{enguehard2017multitask}
\citation{swayamdipta2018scaffold}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Related work}{54}{section*.34}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Multitask learning}{54}{section.5.2}}
\citation{enguehard2017multitask}
\citation{linzen2018targeted}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Multitask objective}{55}{section*.35}}
\newlabel{eq:multitask-objective}{{5.1}{55}{Multitask objective}{equation.5.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Language model}{55}{section*.36}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Word labeling}{55}{section*.37}}
\citation{linzen2018targeted}
\citation{linzen2018targeted}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Span labeling}{56}{section*.38}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Experiments}{56}{section.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Baselines}{56}{subsection.5.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Setup}{56}{subsection.5.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Results}{57}{subsection.5.3.3}}
\citation{williams1992reinforce,fu2006gradient}
\citation{baydin2018automatic}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Semisupervised learning}{58}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{05-semisupervised}{{6}{58}{Semisupervised learning}{chapter.6}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Notation}{58}{section*.39}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Objective}{58}{section.6.1}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Supervised objective}{58}{section*.40}}
\citation{blei2016vi}
\citation{blei2016vi}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Unsupervised objective}{59}{section*.41}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Variational approximation}{59}{section.6.2}}
\newlabel{eq:lowerbound}{{6.1}{59}{Variational approximation}{equation.6.2.1}{}}
\citation{fu2006gradient}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Posterior}{60}{section*.42}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Optimization}{60}{section.6.3}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Gradients of joint parameters}{60}{section*.43}}
\citation{williams1992reinforce,paisley2012viss,mnih2014nvil,ranganath2014black,miao2016discrete}
\citation{williams1992reinforce}
\citation{miao2016discrete}
\citation{rennie2017argmax}
\citation{miao2016discrete,yin2018structvae}
\citation{cheng2017rnng}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Gradients of posterior parameters}{61}{section*.44}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Variance reduction}{61}{section.6.4}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Experiments}{61}{section.6.5}}
\citation{rennie2017argmax}
\citation{klein2018reinforce}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Related work}{62}{section.6.6}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusion}{63}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{07-conclusion}{{7}{63}{Conclusion}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Main contributions}{63}{section.7.1}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Global training of a chart based neural parser.}{63}{section*.45}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Semisupervised training of RNNGs.}{63}{section*.46}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Effective baselines for the score function estimator.}{63}{section*.47}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Future work}{63}{section.7.2}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Something.}{63}{section*.48}}
\citation{cross2016span}
\citation{stern2017minimal,kitaev2018attentive}
\citation{chelba2013one}
\citation{jozefowicz2016exploring}
\citation{merity2016pointer}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Implementation}{64}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{A2-implementation}{{A}{64}{Implementation}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Data}{64}{section.A.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Datasets}{64}{subsection.A.1.1}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Penn Treebank}{64}{section*.49}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline One Billion Word Benchmark}{64}{section*.50}}
\citation{hockenmaier2007ccgbank}
\citation{enguehard2017multitask}
\citation{linzen2018targeted}
\citation{stern2017minimal}
\citation{dyer2016rnng}
\citation{petrov2006learning}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline CCG supertags}{65}{section*.51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.2}Vocabularies}{65}{subsection.A.1.2}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Unknown words}{65}{section*.52}}
\citation{glorot2010understanding}
\citation{peters2018elmo}
\citation{kitaev2018attentive}
\citation{stern2017minimal}
\citation{stern2017minimal}
\citation{stern2018analyis}
\citation{neubig2017dynet}
\citation{neubig2017fly}
\citation{neubig2017dynet,baydin2018automatic}
\citation{wilson2017marginal}
\citation{dyer2016rnng}
\citation{kingma2014adam}
\citation{kingma2014adam}
\citation{ranganath2014black,klein2018reinforce}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Vocabularies\relax }}{66}{table.caption.54}}
\newlabel{tab:vocabularies}{{A.1}{66}{Vocabularies\relax }{table.caption.54}{}}
\newlabel{sec:impl-embedding}{{A.1.2}{66}{Embeddings}{section*.53}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Embeddings}{66}{section*.53}}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Number of parameters in models used.\relax }}{66}{table.caption.55}}
\newlabel{tab:num-params}{{A.2}{66}{Number of parameters in models used.\relax }{table.caption.55}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Implementation}{66}{section.A.2}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Optimization}{66}{section*.56}}
\citation{schulman2015gradient}
\citation{gallo1993directed,klein2004parsing}
\citation{goodman1999semiring,eisner2009semirings}
\citation{klein2004parsing}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Semiring parsing}{68}{appendix.B}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{A3-crf}{{B}{68}{Semiring parsing}{appendix.B}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Hypergraph}{68}{section.B.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.1}{\ignorespaces A fraction of a parse hypergraph showing two possible parses.\relax }}{69}{figure.caption.57}}
\newlabel{fig:hypergraph}{{B.1}{69}{A fraction of a parse hypergraph showing two possible parses.\relax }{figure.caption.57}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.2}Semiring}{69}{section.B.2}}
\citation{goodman1999semiring}
\citation{goodman1999semiring}
\@writefile{toc}{\contentsline {section}{\numberline {B.3}Semiring parsing}{70}{section.B.3}}
\citation{eisner2009semirings}
\citation{goodman1999semiring}
\citation{baker1979trainable}
\newlabel{eq:derivation-weight}{{B.3}{71}{}{equation.B.3.3}{}}
\newlabel{eq:hypergraph-weight}{{B.4}{71}{}{equation.B.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3.1}Inside and outside recursions}{71}{subsection.B.3.1}}
\citation{goodman1999semiring}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3.2}Instantiated recursions}{72}{subsection.B.3.2}}
\newlabel{ex:vit-weight}{{B.3.7}{72}{}{theorem.B.3.7}{}}
\newlabel{ex:vit-derivation}{{B.3.8}{72}{}{theorem.B.3.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {C}Score function estimator}{74}{appendix.C}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{A4-vi}{{C}{74}{Score function estimator}{appendix.C}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C.1}Derivation}{74}{section.C.1}}
\newlabel{eq:score-function-estimator}{{C.1}{74}{Derivation}{equation.C.1.1}{}}
\citation{baydin2017automatic}
\citation{schulman2015gradient}
\citation{paisley2012viss}
\citation{ross2006simulation}
\@writefile{toc}{\contentsline {section}{\numberline {C.2}Optimization}{75}{section.C.2}}
\newlabel{eq:surrogate}{{C.2}{75}{Optimization}{equation.C.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C.3}Variance reduction}{75}{section.C.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3.1}Variance}{76}{subsection.C.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3.2}Control variates}{76}{subsection.C.3.2}}
\citation{ross2006simulation}
\newlabel{eq:cv-scale}{{C.3}{77}{Control variates}{equation.C.3.3}{}}
\newlabel{eq:var-red}{{C.4}{77}{Control variates}{equation.C.3.4}{}}
\citation{linzen2018targeted}
\citation{linzen2018targeted}
\@writefile{toc}{\contentsline {chapter}{\numberline {D}Syneval dataset}{79}{appendix.D}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{A5-syneval}{{D}{79}{Syneval dataset}{appendix.D}{}}
\bibstyle{plainnat}
\bibdata{../src/bibliography.bib}
\bibcite{andor2016globally}{{1}{2016}{{Andor et~al.}}{{Andor, Alberti, Weiss, Severyn, Presta, Ganchev, Petrov, and Collins}}}
\bibcite{baker1979trainable}{{2}{1979}{{Baker}}{{}}}
\bibcite{ballesteros2016exploration}{{3}{2016}{{Ballesteros et~al.}}{{Ballesteros, Goldberg, Dyer, and Smith}}}
\bibcite{bangalore1999supertagging}{{4}{1999}{{Bangalore and Joshi}}{{}}}
\bibcite{baydin2018automatic}{{5}{2018}{{Baydin et~al.}}{{Baydin, Pearlmutter, Radul, and Siskind}}}
\bibcite{bengio2003neural}{{6}{2003}{{Bengio et~al.}}{{Bengio, Ducharme, Vincent, and Jauvin}}}
\bibcite{black1991parseval}{{7}{1991}{{Black et~al.}}{{Black, Abney, Flickenger, Gdaniec, Grishman, Harrison, Hindle, Ingria, Jelinek, Klavans, et~al.}}}
\bibcite{blei2016vi}{{8}{2016}{{Blei et~al.}}{{Blei, Kucukelbir, and McAuliffe}}}
\bibcite{brennan2016abstract}{{9}{2016}{{Brennan et~al.}}{{Brennan, Stabler, Van~Wagenen, Luh, and Hale}}}
\bibcite{buys2015bayesian}{{10}{2015{a}}{{Buys and Blunsom}}{{}}}
\bibcite{buys2015generative}{{11}{2015{b}}{{Buys and Blunsom}}{{}}}
\bibcite{buys2018exact}{{12}{2018}{{Buys and Blunsom}}{{}}}
\bibcite{carnie2010constituent}{{13}{2010}{{Carnie}}{{}}}
\bibcite{caruana1997multitask}{{14}{1997}{{Caruana}}{{}}}
\bibcite{chelba2000structured}{{15}{2000}{{Chelba and Jelinek}}{{}}}
\bibcite{chelba2013one}{{16}{2013}{{Chelba et~al.}}{{Chelba, Mikolov, Schuster, Ge, Brants, Koehn, and Robinson}}}
\bibcite{chelba2017n}{{17}{2017}{{Chelba et~al.}}{{Chelba, Norouzi, and Bengio}}}
\bibcite{chen1999empirical}{{18}{1999}{{Chen and Goodman}}{{}}}
\bibcite{cheng2017rnng}{{19}{2017}{{Cheng et~al.}}{{Cheng, Lopez, and Lapata}}}
\bibcite{chomsky1980rules}{{20}{1980}{{Chomsky}}{{}}}
\bibcite{christiansen2012similar}{{21}{2012}{{Christiansen et~al.}}{{Christiansen, Conway, and Onnis}}}
\bibcite{collins2003head}{{22}{2003}{{Collins}}{{}}}
\bibcite{collobert2008unified}{{23}{2008}{{Collobert and Weston}}{{}}}
\bibcite{collobert2011natural}{{24}{2011}{{Collobert et~al.}}{{Collobert, Weston, Bottou, Karlen, Kavukcuoglu, and Kuksa}}}
\bibcite{conway2008neurocognitive}{{25}{2008}{{Conway and Pisoni}}{{}}}
\bibcite{cross2016span}{{26}{2016}{{Cross and Huang}}{{}}}
\bibcite{dozat2016deep}{{27}{2016}{{Dozat and Manning}}{{}}}
\bibcite{klein2015crf}{{28}{2015}{{Durrett and Klein}}{{}}}
\bibcite{dyer2016rnng}{{29}{2016}{{Dyer et~al.}}{{Dyer, Kuncoro, Ballesteros, and Smith}}}
\bibcite{eisner2016backprop}{{30}{2016}{{Eisner}}{{}}}
\bibcite{emami2005neural}{{31}{2005}{{Emami and Jelinek}}{{}}}
\bibcite{enguehard2017multitask}{{32}{2017}{{Enguehard et~al.}}{{Enguehard, Goldberg, and Linzen}}}
\bibcite{everaert2015structures}{{33}{2015}{{Everaert et~al.}}{{Everaert, Huybregts, Chomsky, Berwick, and Bolhuis}}}
\bibcite{finkel2008crf}{{34}{2008}{{Finkel et~al.}}{{Finkel, Kleeman, and Manning}}}
\bibcite{frank2012hierarchical}{{35}{2012}{{Frank et~al.}}{{Frank, Bod, and Christiansen}}}
\bibcite{klein2018reinforce}{{36}{2018}{{Fried and Klein}}{{}}}
\bibcite{fu2006gradient}{{37}{2006}{{Fu}}{{}}}
\bibcite{stern2018analyis}{{38}{2018}{{Gaddy et~al.}}{{Gaddy, Stern, and Klein}}}
\bibcite{gal2016theoretically}{{39}{2016}{{Gal and Ghahramani}}{{}}}
\bibcite{gallo1993directed}{{40}{1993}{{Gallo et~al.}}{{Gallo, Longo, Pallottino, and Nguyen}}}
\bibcite{giannakidou2011npi}{{41}{2011}{{Giannakidou}}{{}}}
\bibcite{gillespie2011hierarchy}{{42}{2011}{{Gillespie and Pearlmutter}}{{}}}
\bibcite{gillespie2013against}{{43}{2013}{{Gillespie and Pearlmutter}}{{}}}
\bibcite{glorot2010understanding}{{44}{2010}{{Glorot and Bengio}}{{}}}
\bibcite{goldberg2013dynamic}{{45}{2013}{{Goldberg and Nivre}}{{}}}
\bibcite{goodman1999semiring}{{46}{1999}{{Goodman}}{{}}}
\bibcite{gulordava2018colorless}{{47}{2018}{{Gulordava et~al.}}{{Gulordava, Bojanowski, Grave, Linzen, and Baroni}}}
\bibcite{hale2001earley}{{48}{2001}{{Hale}}{{}}}
\bibcite{hale2018beam}{{49}{2018}{{Hale et~al.}}{{Hale, Dyer, Kuncoro, and Brennan}}}
\bibcite{hall2014less}{{50}{2014}{{Hall et~al.}}{{Hall, Durrett, and Klein}}}
\bibcite{he2012imitation}{{51}{2012}{{He et~al.}}{{He, Eisner, and Daume}}}
\bibcite{hochreiter1997long}{{52}{1997}{{Hochreiter and Schmidhuber}}{{}}}
\bibcite{hockenmaier2007ccgbank}{{53}{2007}{{Hockenmaier and Steedman}}{{}}}
\bibcite{huddleston2002grammar}{{54}{2002}{{Huddleston and Pullum}}{{}}}
\bibcite{hudson2010introduction}{{55}{2010}{{Hudson}}{{}}}
\bibcite{jelinek1997information}{{56}{1997}{{Jelinek}}{{}}}
\bibcite{jozefowicz2016exploring}{{57}{2016}{{Jozefowicz et~al.}}{{Jozefowicz, Vinyals, Schuster, Shazeer, and Wu}}}
\bibcite{kalchbrenner2014convolutional}{{58}{2014}{{Kalchbrenner et~al.}}{{Kalchbrenner, Grefenstette, and Blunsom}}}
\bibcite{kim2017structured}{{59}{2017}{{Kim et~al.}}{{Kim, Denton, Hoang, and Rush}}}
\bibcite{kingma2014adam}{{60}{2014}{{Kingma and Ba}}{{}}}
\bibcite{kitaev2018attentive}{{61}{2018}{{Kitaev and Klein}}{{}}}
\bibcite{klein2003accurate}{{62}{2003}{{Klein and Manning}}{{}}}
\bibcite{klein2004parsing}{{63}{2004}{{Klein and Manning}}{{}}}
\bibcite{kneser1995improved}{{64}{1995}{{Kneser and Ney}}{{}}}
\bibcite{kuncoro2017syntax}{{65}{2017}{{Kuncoro et~al.}}{{Kuncoro, Ballesteros, Kong, Dyer, Neubig, and Smith}}}
\bibcite{kuncoro2018learn}{{66}{2018}{{Kuncoro et~al.}}{{Kuncoro, Dyer, Hale, Yogatama, Clark, and Blunsom}}}
\bibcite{lafferty2001crf}{{67}{2001}{{Lafferty et~al.}}{{Lafferty, McCallum, and Pereira}}}
\bibcite{levy2008expectation}{{68}{2008}{{Levy}}{{}}}
\bibcite{eisner2009semirings}{{69}{2009}{{Li and Eisner}}{{}}}
\bibcite{linzen2016syntax}{{70}{2016}{{Linzen et~al.}}{{Linzen, Dupoux, and Goldberg}}}
\bibcite{marcus1994annotating}{{71}{1994}{{Marcus et~al.}}{{Marcus, Kim, Marcinkiewicz, MacIntyre, Bies, Ferguson, Katz, and Schasberger}}}
\bibcite{marcus1993penn}{{72}{1993}{{Marcus et~al.}}{{Marcus, Marcinkiewicz, and Santorini}}}
\bibcite{linzen2018targeted}{{73}{2018}{{Marvin and Linzen}}{{}}}
\bibcite{mccoy2018revisiting}{{74}{2018}{{McCoy et~al.}}{{McCoy, Linzen, and Frank}}}
\bibcite{melis2017state}{{75}{2017}{{Melis et~al.}}{{Melis, Dyer, and Blunsom}}}
\bibcite{merity2016pointer}{{76}{2016}{{Merity et~al.}}{{Merity, Xiong, Bradbury, and Socher}}}
\bibcite{miao2016discrete}{{77}{2016}{{Miao and Blunsom}}{{}}}
\bibcite{mikolov2010recurrent}{{78}{2010}{{Mikolov et~al.}}{{Mikolov, Karafi{\'a}t, Burget, {\v {C}}ernock{\`y}, and Khudanpur}}}
\bibcite{mnih2014nvil}{{79}{2014}{{Mnih and Gregor}}{{}}}
\bibcite{neubig2017dynet}{{80}{2017{a}}{{Neubig et~al.}}{{Neubig, Dyer, Goldberg, Matthews, Ammar, Anastasopoulos, Ballesteros, Chiang, Clothiaux, Cohn, et~al.}}}
\bibcite{neubig2017fly}{{81}{2017{b}}{{Neubig et~al.}}{{Neubig, Goldberg, and Dyer}}}
\bibcite{nivre2005dependency}{{82}{2005}{{Nivre}}{{}}}
\bibcite{paisley2012viss}{{83}{2012}{{Paisley et~al.}}{{Paisley, Blei, and Jordan}}}
\bibcite{pauls2012treelets}{{84}{2012}{{Pauls and Klein}}{{}}}
\bibcite{peters2018elmo}{{85}{2018}{{Peters et~al.}}{{Peters, Neumann, Iyyer, Gardner, Clark, Lee, and Zettlemoyer}}}
\bibcite{petrov2006learning}{{86}{2006}{{Petrov et~al.}}{{Petrov, Barrett, Thibaux, and Klein}}}
\bibcite{ranganath2014black}{{87}{2014}{{Ranganath et~al.}}{{Ranganath, Gerrish, and Blei}}}
\bibcite{rennie2017argmax}{{88}{2017}{{Rennie et~al.}}{{Rennie, Marcheret, Mroueh, Ross, and Goel}}}
\bibcite{roark2001probabilistic}{{89}{2001}{{Roark}}{{}}}
\bibcite{rosenfeld1996loglinear}{{90}{1996}{{Rosenfeld}}{{}}}
\bibcite{ross2006simulation}{{91}{2006}{{Ross}}{{}}}
\bibcite{schulman2015gradient}{{92}{2015}{{Schulman et~al.}}{{Schulman, Heess, Weber, and Abbeel}}}
\bibcite{sekine1997evalb}{{93}{1997}{{Sekine and Collins}}{{}}}
\bibcite{sennrich2017grammatical}{{94}{2017}{{Sennrich}}{{}}}
\bibcite{smith2012adversarial}{{95}{2012}{{Smith}}{{}}}
\bibcite{goldberg2016multitask}{{96}{2016}{{S{\o }gaard and Goldberg}}{{}}}
\bibcite{stern2017minimal}{{97}{2017{a}}{{Stern et~al.}}{{Stern, Andreas, and Klein}}}
\bibcite{stern2017beam}{{98}{2017{b}}{{Stern et~al.}}{{Stern, Fried, and Klein}}}
\bibcite{swayamdipta2018scaffold}{{99}{2018}{{Swayamdipta et~al.}}{{Swayamdipta, Thomson, Lee, Zettlemoyer, Dyer, and Smith}}}
\bibcite{tesniere1959elements}{{100}{1959}{{Tesni{\`e}re}}{{}}}
\bibcite{titov2007generative}{{101}{2007}{{Titov and Henderson}}{{}}}
\bibcite{tran2018recurrent}{{102}{2018}{{Tran et~al.}}{{Tran, Bisazza, and Monz}}}
\bibcite{vaswani2017attention}{{103}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{vlachos2012imitation}{{104}{2013}{{Vlachos}}{{}}}
\bibcite{warstadt2018acceptability}{{105}{2018}{{Warstadt et~al.}}{{Warstadt, Singh, and Bowman}}}
\bibcite{williams1992reinforce}{{106}{1992}{{Williams}}{{}}}
\bibcite{wilson2017marginal}{{107}{2017}{{Wilson et~al.}}{{Wilson, Roelofs, Stern, Srebro, and Recht}}}
\bibcite{xiang2009illusory}{{108}{2009}{{Xiang et~al.}}{{Xiang, Dillon, and Phillips}}}
\bibcite{yin2018structvae}{{109}{2018}{{Yin et~al.}}{{Yin, Zhou, He, and Neubig}}}
\bibcite{zaremba2014recurrent}{{110}{2014}{{Zaremba et~al.}}{{Zaremba, Sutskever, and Vinyals}}}
\bibcite{zhang2016multitask}{{111}{2016}{{Zhang and Weiss}}{{}}}
\bibcite{zweig2011microsoft}{{112}{2011}{{Zweig and Burges}}{{}}}
\global\csname @altsecnumformattrue\endcsname
\global\@namedef{scr@dte@chapter@lastmaxnumwidth}{16.23872pt}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{23.84888pt}
\global\@namedef{scr@dte@subsection@lastmaxnumwidth}{32.06136pt}
