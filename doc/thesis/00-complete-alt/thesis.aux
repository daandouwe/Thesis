\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\new@tpo@label[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{dyer2016rnng,buys2015generative,buys2018exact}
\citation{dyer2016rnng}
\citation{buys2018exact}
\citation{dyer2016rnng}
\citation{stern2017minimal}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{7}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{01-introduction}{{1}{7}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline The approximate marginalization}{7}{section*.4}}
\citation{fu2006gradient}
\citation{williams1992reinforce}
\citation{rennie2017argmax}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Semi-supervised training by including unlabeled data}{8}{section*.5}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Alternative, simpler, models}{8}{section*.6}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Targeted syntactic evaluation}{8}{section*.7}}
\citation{huddleston2002grammar}
\citation{carnie2010constituent}
\citation{everaert2015structures}
\citation{huddleston2002grammar}
\citation{carnie2010constituent}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{9}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{02-background}{{2}{9}{Background}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Syntax}{9}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Constituents}{9}{subsection.2.1.1}}
\citation{carnie2010constituent}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:bird-tree}{{\caption@xref {fig:bird-tree}{ on input line 28}}{10}{Constituents}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Categories}{10}{subsection.2.1.2}}
\citation{everaert2015structures}
\citation{everaert2015structures}
\citation{everaert2015structures}
\citation{giannakidou2011npi}
\citation{everaert2015structures}
\citation{everaert2015structures}
\citation{everaert2015structures}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Hierarchy}{11}{subsection.2.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Hierarchical dependance of negative polarity items. Left shows the word \textit  {anybody} in the licensing context of \textit  {not}, while right shows the ungrammatical sentence where the word is not. Figure taken without permission from \cite  {everaert2015structures}.\relax }}{11}{figure.caption.10}}
\newlabel{fig:trees-npi}{{2.1}{11}{Hierarchical dependance of negative polarity items. Left shows the word \textit {anybody} in the licensing context of \textit {not}, while right shows the ungrammatical sentence where the word is not. Figure taken without permission from \cite {everaert2015structures}.\relax }{figure.caption.10}{}}
\newlabel{ref:trees-npi}{{(3)}{11}{Hierarchy}{figure.caption.10}{}}
\citation{tesniere1959elements,nivre2005dependency,hudson2010introduction}
\citation{frank2012hierarchical}
\citation{everaert2015structures}
\citation{hale2001earley,levy2008expectation,brennan2016abstract}
\citation{conway2008neurocognitive,gillespie2011hierarchy,christiansen2012similar,gillespie2013against,frank2012hierarchical}
\citation{marcus1993penn}
\citation{marcus1994annotating}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Controversy}{12}{subsection.2.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Parsing}{12}{section.2.2}}
\citation{andor2016globally}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Treebank}{13}{subsection.2.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Two representations of the tree in \ref  {fig:tree-cnf-spans}.\relax }}{13}{table.caption.12}}
\newlabel{tab:spans-rules}{{2.1}{13}{Two representations of the tree in \ref {fig:tree-cnf-spans}.\relax }{table.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Models}{13}{subsection.2.2.2}}
\citation{lafferty2001crf}
\citation{lafferty2001crf}
\citation{goldberg2013dynamic}
\citation{ballesteros2016exploration,stern2017minimal}
\citation{vlachos2012imitation,he2012imitation}
\citation{ballesteros2016exploration}
\citation{klein2018reinforce}
\citation{black1991parseval}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Metrics}{15}{subsection.2.2.3}}
\newlabel{eq:fscore}{{2.1}{15}{Metrics}{equation.2.2.1}{}}
\citation{sekine1997evalb}
\citation{chen1999empirical,kneser1995improved}
\citation{rosenfeld1996loglinear,bengio2003neural}
\citation{mikolov2010recurrent}
\citation{hochreiter1997long}
\citation{zaremba2014recurrent,jozefowicz2016exploring,melis2017state}
\citation{chelba2017n}
\citation{kalchbrenner2014convolutional}
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Language models}{16}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Models}{16}{subsection.2.3.1}}
\newlabel{eq:lm-factorized}{{2.2}{16}{Models}{equation.2.3.2}{}}
\citation{roark2001probabilistic}
\citation{chelba2000structured,emami2005neural}
\citation{pauls2012treelets}
\citation{chelba2013one}
\citation{merity2016pointer}
\citation{jelinek1997information}
\citation{chelba2017n}
\newlabel{eq:lm-latent}{{2.3}{17}{Models}{equation.2.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Data}{17}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Metrics}{17}{subsection.2.3.3}}
\citation{smith2012adversarial}
\citation{linzen2016syntax}
\citation{linzen2018targeted}
\citation{linzen2018targeted}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Neural networks}{18}{section.2.4}}
\citation{hochreiter1997long}
\newlabel{fig:tree-original}{{2.2a}{20}{Original Penn Treebank tree.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:tree-original}{{a}{20}{Original Penn Treebank tree.\relax }{figure.caption.11}{}}
\newlabel{fig:tree-simplified}{{2.2b}{20}{Function tags and traces removed.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:tree-simplified}{{b}{20}{Function tags and traces removed.\relax }{figure.caption.11}{}}
\newlabel{fig:tree-cnf}{{2.2c}{20}{Converted to normal form.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:tree-cnf}{{c}{20}{Converted to normal form.\relax }{figure.caption.11}{}}
\newlabel{fig:tree-cnf-spans}{{2.2d}{20}{In normal form with spans.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:tree-cnf-spans}{{d}{20}{In normal form with spans.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Converting a treebank tree (withouth part-of-speech tags).\relax }}{20}{figure.caption.11}}
\newlabel{fig:trees-ptb}{{2.2}{20}{Converting a treebank tree (withouth part-of-speech tags).\relax }{figure.caption.11}{}}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Recurrent Neural Network Grammars}{21}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{03-rnng}{{3}{21}{Recurrent Neural Network Grammars}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Model}{21}{section.3.1}}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Transition sytem}{22}{subsection.3.1.1}}
\newlabel{ex:disc-states}{{3.1.1}{22}{}{theorem.3.1.1}{}}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Model}{23}{subsection.3.1.2}}
\newlabel{eq:naive-rnng-model}{{3.1}{23}{Model}{equation.3.1.1}{}}
\newlabel{eq:disc-model}{{3.4}{24}{}{equation.3.1.4}{}}
\newlabel{eq:disc-model}{{3.5}{24}{}{equation.3.1.5}{}}
\newlabel{eq:disc-model}{{3.6}{24}{}{equation.3.1.6}{}}
\newlabel{eq:gen-model}{{3.7}{24}{}{equation.3.1.7}{}}
\citation{dyer2016rnng}
\citation{hale2018beam}
\newlabel{eq:action-regression}{{3.8}{25}{Model}{equation.3.1.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Parametrization}{25}{section.3.2}}
\citation{dyer2016rnng}
\citation{kuncoro2017syntax}
\citation{kuncoro2017syntax}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Stack encoder}{26}{subsection.3.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Composition function}{27}{subsection.3.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Training}{27}{section.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Inference}{27}{section.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Discriminative model}{27}{subsection.3.4.1}}
\citation{dyer2016rnng}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Generative model}{28}{subsection.3.4.2}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Approximate marginalization}{28}{section*.15}}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{dyer2016rnng}
\citation{kuncoro2017syntax}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Approximate MAP tree}{29}{section*.16}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Proposal distribution}{29}{section*.17}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Experiments}{29}{section.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Supervised models}{29}{subsection.3.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Sampler}{29}{subsection.3.5.2}}
\citation{titov2007generative,buys2015bayesian,buys2015generative,buys2018exact}
\citation{roark2001probabilistic}
\citation{kuncoro2017syntax}
\citation{linzen2016syntax,kuncoro2018learn}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces F1 scores for the discriminative RNNG. The first value shows the mean and standard deviation over 10 models trained from different random seeds. The second value (in brackets) shows the score of the single model selected by development score. Note that our rnng is trained without tags.\relax }}{30}{table.caption.18}}
\newlabel{tab:disc-fscores}{{3.1}{30}{F1 scores for the discriminative RNNG. The first value shows the mean and standard deviation over 10 models trained from different random seeds. The second value (in brackets) shows the score of the single model selected by development score. Note that our rnng is trained without tags.\relax }{table.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces F1 scores for the generative RNNG, for different proposal models. The first column is with proposals from our discriminative RNNG, the final column is with the proposals used by \citet  {dyer2016rnng} to evaluate, availlable at \url  {https://github.com/clab/rnng}.\relax }}{30}{table.caption.19}}
\newlabel{tab:gen-fscores}{{3.2}{30}{F1 scores for the generative RNNG, for different proposal models. The first column is with proposals from our discriminative RNNG, the final column is with the proposals used by \citet {dyer2016rnng} to evaluate, availlable at \url {https://github.com/clab/rnng}.\relax }{table.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Related work}{30}{section.3.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Generative parsing}{30}{subsection.3.6.1}}
\citation{brennan2016abstract}
\citation{hale2018beam}
\citation{stern2017beam}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Perplexity on the PTB of the generative RNNG, for different proposal models. See \ref  {tab:gen-fscores} for explanation of the proposals.\relax }}{31}{table.caption.20}}
\newlabel{tab:gen-perplexities}{{3.3}{31}{Perplexity on the PTB of the generative RNNG, for different proposal models. See \ref {tab:gen-fscores} for explanation of the proposals.\relax }{table.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Syntax}{31}{subsection.3.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}Cognition}{31}{subsection.3.6.3}}
\citation{stern2017minimal}
\citation{stern2017minimal}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Conditional Random Field parser}{32}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{04-crf}{{4}{32}{Conditional Random Field parser}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Model}{32}{section.4.1}}
\citation{finkel2008crf,klein2015crf}
\citation{stern2017minimal}
\citation{stern2017minimal}
\newlabel{eq:crf-model}{{4.1}{33}{Model}{equation.4.1.1}{}}
\citation{stern2017minimal}
\citation{dozat2016deep}
\citation{stern2018analyis}
\citation{stern2018analyis}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Representation for the span $(1, 4)$ computed from $\textsc  {Rnn}$ encodings. Taken from \citet  {stern2018analyis}.\relax }}{34}{figure.caption.21}}
\newlabel{fig:span-feature}{{4.1}{34}{Representation for the span $(1, 4)$ computed from $\rnn $ encodings. Taken from \citet {stern2018analyis}.\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Parametrization}{34}{section.4.2}}
\newlabel{eq:span-feature}{{4.3}{34}{Parametrization}{equation.4.2.3}{}}
\newlabel{eq:potential-function}{{4.4}{34}{Parametrization}{equation.4.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Inference}{34}{section.4.3}}
\newlabel{sect:inference}{{4.3}{34}{Inference}{section.4.3}{}}
\citation{baker1979trainable}
\citation{goodman1999semiring}
\citation{gallo1993directed,klein2004parsing}
\citation{goodman1999semiring,eisner2009semirings}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Weighted parse forest}{35}{subsection.4.3.1}}
\citation{goodman1999semiring}
\newlabel{fig:crf-edges}{{\caption@xref {fig:crf-edges}{ on input line 85}}{36}{Weighted parse forest}{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces The edge-types making up the hypergraph. The edges are instatiated for all $A, B, C \in \Lambda $ and all $0 \leq i < j \leq n$. Only for the rightmost edge holds the restriction $A \not =\varnothing $, to ensure that the dummy label cannot be the top node.\relax }}{36}{figure.caption.22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Inside recursion}{36}{subsection.4.3.2}}
\newlabel{eq:inside-base}{{4.5}{37}{Inside recursion}{equation.4.3.5}{}}
\newlabel{eq:inside}{{4.6}{37}{Inside recursion}{equation.4.3.6}{}}
\newlabel{eq:inside-simplified}{{4.7}{37}{Inside recursion}{equation.4.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Outside recursion}{38}{subsection.4.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Solutions}{39}{subsection.4.3.4}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Normalizer}{39}{section*.23}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Parse}{39}{section*.24}}
\newlabel{eq:viterbi-score}{{4.8}{39}{Parse}{equation.4.3.8}{}}
\newlabel{eq:viterbi-tree}{{4.10}{39}{Parse}{equation.4.3.10}{}}
\citation{goodman1999semiring}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Sample}{40}{section*.25}}
\newlabel{eq:sample}{{4.12}{40}{Sample}{equation.4.3.12}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Entropy}{40}{section*.26}}
\newlabel{eq:node-marginal}{{4.13}{40}{Entropy}{equation.4.3.13}{}}
\citation{eisner2009semirings}
\citation{eisner2016backprop}
\citation{kim2017structured}
\citation{stern2017minimal}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Traning}{41}{section.4.4}}
\citation{stern2017minimal}
\citation{stern2017minimal}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Experiments}{42}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Supervised model}{42}{subsection.4.5.1}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces F1 scores for the CRF.\relax }}{42}{table.caption.27}}
\newlabel{tab:disc-fscores}{{4.1}{42}{F1 scores for the CRF.\relax }{table.caption.27}{}}
\citation{buys2018exact}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Proposal model}{43}{subsection.4.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}Sampler}{43}{subsection.4.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Problems as proposal}{44}{section.4.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Two normal form derivations that collapse to the same tree.\relax }}{44}{figure.caption.28}}
\newlabel{fig:normal-form-trees}{{4.3}{44}{Two normal form derivations that collapse to the same tree.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Unrestricted parse forest}{45}{subsection.4.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Pruned parse forest}{46}{subsection.4.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Edges in the parse forest that produce the derivational ambiguity, whenever $k > i+1$.\relax }}{47}{figure.caption.29}}
\newlabel{fig:illegal-edges}{{4.4}{47}{Edges in the parse forest that produce the derivational ambiguity, whenever $k > i+1$.\relax }{figure.caption.29}{}}
\citation{finkel2008crf,klein2015crf}
\citation{stern2017minimal}
\citation{hall2014less}
\citation{finkel2008crf}
\citation{klein2015crf}
\citation{stern2017minimal}
\citation{collins2003head}
\citation{klein2003accurate}
\citation{petrov2006learning}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Related work}{48}{section.4.7}}
\citation{klein2015crf}
\citation{linzen2018targeted}
\citation{enguehard2017multitask}
\citation{linzen2018targeted}
\citation{linzen2018targeted}
\citation{linzen2016syntax,gulordava2018colorless,linzen2018targeted}
\citation{linzen2016syntax}
\citation{tran2018recurrent}
\citation{kuncoro2018learn}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Syntactic evaluation}{50}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{06-syneval}{{5}{50}{Syntactic evaluation}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Syntactic evaluation}{50}{section.5.1}}
\citation{linzen2016syntax}
\citation{kuncoro2018learn}
\citation{everaert2015structures,xiang2009illusory}
\citation{linzen2016syntax}
\citation{gulordava2018colorless}
\citation{gulordava2018colorless}
\citation{warstadt2018acceptability}
\citation{mccoy2018revisiting}
\citation{everaert2015structures}
\citation{chomsky1980rules}
\citation{zweig2011microsoft}
\citation{sennrich2017grammatical}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Dataset}{51}{section*.30}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Categories}{51}{section*.31}}
\citation{enguehard2017multitask,linzen2018targeted}
\citation{caruana1997multitask}
\citation{collobert2008unified,collobert2011natural,zhang2016multitask,goldberg2016multitask}
\citation{bangalore1999supertagging}
\citation{enguehard2017multitask}
\citation{swayamdipta2018scaffold}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Related work}{52}{section*.32}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Multitask learning}{52}{section.5.2}}
\citation{enguehard2017multitask}
\citation{linzen2018targeted}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Multitask objective}{53}{section*.33}}
\newlabel{eq:multitask-objective}{{5.1}{53}{Multitask objective}{equation.5.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Language model}{53}{section*.34}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Word labeling}{53}{section*.35}}
\citation{linzen2018targeted}
\citation{linzen2018targeted}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Span labeling}{54}{section*.36}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Experiments}{54}{section.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Baselines}{54}{subsection.5.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Setup}{55}{subsection.5.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Results}{55}{subsection.5.3.3}}
\citation{williams1992reinforce,fu2006gradient}
\citation{baydin2018automatic}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Semisupervised learning}{56}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{05-semisupervised}{{6}{56}{Semisupervised learning}{chapter.6}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Notation}{56}{section*.37}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Objective}{56}{section.6.1}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Supervised objective}{56}{section*.38}}
\citation{blei2016vi}
\citation{blei2016vi}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Unsupervised objective}{57}{section*.39}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Variational approximation}{57}{section.6.2}}
\newlabel{eq:lowerbound}{{6.1}{57}{Variational approximation}{equation.6.2.1}{}}
\citation{fu2006gradient}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Posterior}{58}{section*.40}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Optimization}{58}{section.6.3}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Gradients of joint parameters}{58}{section*.41}}
\citation{williams1992reinforce,paisley2012viss,mnih2014nvil,ranganath2014black,miao2016discrete}
\citation{williams1992reinforce}
\citation{miao2016discrete}
\citation{rennie2017argmax}
\citation{miao2016discrete,yin2018structvae}
\citation{cheng2017rnng}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Gradients of posterior parameters}{59}{section*.42}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Variance reduction}{59}{section.6.4}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Experiments}{59}{section.6.5}}
\citation{rennie2017argmax}
\citation{klein2018reinforce}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Related work}{60}{section.6.6}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusion}{61}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{07-conclusion}{{7}{61}{Conclusion}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Main contributions}{61}{section.7.1}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Global training of a chart based neural parser.}{61}{section*.43}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Semisupervised training of RNNGs.}{61}{section*.44}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Effective baselines for the score function estimator.}{61}{section*.45}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Future work}{61}{section.7.2}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Something.}{61}{section*.46}}
\citation{cross2016span}
\citation{stern2017minimal,kitaev2018attentive}
\citation{chelba2013one}
\citation{jozefowicz2016exploring}
\citation{merity2016pointer}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Implementation}{62}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{A2-implementation}{{A}{62}{Implementation}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Data}{62}{section.A.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Datasets}{62}{subsection.A.1.1}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Penn Treebank}{62}{section*.47}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline One Billion Word Benchmark}{62}{section*.48}}
\citation{hockenmaier2007ccgbank}
\citation{enguehard2017multitask}
\citation{linzen2018targeted}
\citation{stern2017minimal}
\citation{dyer2016rnng}
\citation{petrov2006learning}
\citation{dyer2016rnng}
\citation{glorot2010understanding}
\citation{peters2018elmo}
\citation{kitaev2018attentive}
\citation{stern2017minimal}
\citation{stern2017minimal}
\citation{stern2018analyis}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline CCG supertags}{63}{section*.49}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.2}Vocabularies}{63}{subsection.A.1.2}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Unknown words}{63}{section*.50}}
\citation{neubig2017dynet}
\citation{neubig2017fly}
\citation{neubig2017dynet,baydin2018automatic}
\citation{wilson2017marginal}
\citation{dyer2016rnng}
\citation{kingma2014adam}
\citation{kingma2014adam}
\citation{ranganath2014black,klein2018reinforce}
\citation{mnih2014nvil}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Vocabularies\relax }}{64}{table.caption.52}}
\newlabel{tab:vocabularies}{{A.1}{64}{Vocabularies\relax }{table.caption.52}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Embeddings}{64}{section*.51}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Implementation}{64}{section.A.2}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Optimization}{64}{section*.53}}
\citation{schulman2015gradient}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Optimization\relax }}{65}{table.caption.54}}
\newlabel{tab:optimization}{{A.2}{65}{Optimization\relax }{table.caption.54}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.3}{\ignorespaces Model parameters\relax }}{65}{table.caption.56}}
\newlabel{tab:model-parameters}{{A.3}{65}{Model parameters\relax }{table.caption.56}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Hyperparameters}{65}{section*.55}}
\citation{gallo1993directed,klein2004parsing}
\citation{goodman1999semiring,eisner2009semirings}
\citation{klein2004parsing}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Semiring parsing}{66}{appendix.B}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{A3-crf}{{B}{66}{Semiring parsing}{appendix.B}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Hypergraph}{66}{section.B.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.1}{\ignorespaces A fraction of a parse hypergraph showing two possible parses.\relax }}{67}{figure.caption.57}}
\newlabel{fig:hypergraph}{{B.1}{67}{A fraction of a parse hypergraph showing two possible parses.\relax }{figure.caption.57}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.2}Semiring}{67}{section.B.2}}
\citation{goodman1999semiring}
\citation{goodman1999semiring}
\@writefile{toc}{\contentsline {section}{\numberline {B.3}Semiring parsing}{68}{section.B.3}}
\citation{eisner2009semirings}
\citation{goodman1999semiring}
\citation{baker1979trainable}
\newlabel{eq:derivation-weight}{{B.3}{69}{}{equation.B.3.3}{}}
\newlabel{eq:hypergraph-weight}{{B.4}{69}{}{equation.B.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3.1}Inside and outside recursions}{69}{subsection.B.3.1}}
\citation{goodman1999semiring}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3.2}Instantiated recursions}{70}{subsection.B.3.2}}
\newlabel{ex:vit-weight}{{B.3.7}{70}{}{theorem.B.3.7}{}}
\newlabel{ex:vit-derivation}{{B.3.8}{70}{}{theorem.B.3.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {C}Score function estimator}{72}{appendix.C}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{A4-vi}{{C}{72}{Score function estimator}{appendix.C}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C.1}Derivation}{72}{section.C.1}}
\newlabel{eq:score-function-estimator}{{C.1}{72}{Derivation}{equation.C.1.1}{}}
\citation{baydin2017automatic}
\citation{schulman2015gradient}
\citation{paisley2012viss}
\citation{ross2006simulation}
\@writefile{toc}{\contentsline {section}{\numberline {C.2}Optimization}{73}{section.C.2}}
\newlabel{eq:surrogate}{{C.2}{73}{Optimization}{equation.C.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C.3}Variance reduction}{73}{section.C.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3.1}Variance}{74}{subsection.C.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3.2}Control variates}{74}{subsection.C.3.2}}
\citation{ross2006simulation}
\newlabel{eq:cv-scale}{{C.3}{75}{Control variates}{equation.C.3.3}{}}
\newlabel{eq:var-red}{{C.4}{75}{Control variates}{equation.C.3.4}{}}
\citation{linzen2018targeted}
\citation{linzen2018targeted}
\@writefile{toc}{\contentsline {chapter}{\numberline {D}Syneval dataset}{77}{appendix.D}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{A5-syneval}{{D}{77}{Syneval dataset}{appendix.D}{}}
\bibstyle{plainnat}
\bibdata{../src/bibliography.bib}
\bibcite{andor2016globally}{{1}{2016}{{Andor et~al.}}{{Andor, Alberti, Weiss, Severyn, Presta, Ganchev, Petrov, and Collins}}}
\bibcite{baker1979trainable}{{2}{1979}{{Baker}}{{}}}
\bibcite{ballesteros2016exploration}{{3}{2016}{{Ballesteros et~al.}}{{Ballesteros, Goldberg, Dyer, and Smith}}}
\bibcite{bangalore1999supertagging}{{4}{1999}{{Bangalore and Joshi}}{{}}}
\bibcite{baydin2018automatic}{{5}{2018}{{Baydin et~al.}}{{Baydin, Pearlmutter, Radul, and Siskind}}}
\bibcite{bengio2003neural}{{6}{2003}{{Bengio et~al.}}{{Bengio, Ducharme, Vincent, and Jauvin}}}
\bibcite{black1991parseval}{{7}{1991}{{Black et~al.}}{{Black, Abney, Flickenger, Gdaniec, Grishman, Harrison, Hindle, Ingria, Jelinek, Klavans, et~al.}}}
\bibcite{blei2016vi}{{8}{2016}{{Blei et~al.}}{{Blei, Kucukelbir, and McAuliffe}}}
\bibcite{brennan2016abstract}{{9}{2016}{{Brennan et~al.}}{{Brennan, Stabler, Van~Wagenen, Luh, and Hale}}}
\bibcite{buys2015bayesian}{{10}{2015{a}}{{Buys and Blunsom}}{{}}}
\bibcite{buys2015generative}{{11}{2015{b}}{{Buys and Blunsom}}{{}}}
\bibcite{buys2018exact}{{12}{2018}{{Buys and Blunsom}}{{}}}
\bibcite{carnie2010constituent}{{13}{2010}{{Carnie}}{{}}}
\bibcite{caruana1997multitask}{{14}{1997}{{Caruana}}{{}}}
\bibcite{chelba2000structured}{{15}{2000}{{Chelba and Jelinek}}{{}}}
\bibcite{chelba2013one}{{16}{2013}{{Chelba et~al.}}{{Chelba, Mikolov, Schuster, Ge, Brants, Koehn, and Robinson}}}
\bibcite{chelba2017n}{{17}{2017}{{Chelba et~al.}}{{Chelba, Norouzi, and Bengio}}}
\bibcite{chen1999empirical}{{18}{1999}{{Chen and Goodman}}{{}}}
\bibcite{cheng2017rnng}{{19}{2017}{{Cheng et~al.}}{{Cheng, Lopez, and Lapata}}}
\bibcite{chomsky1980rules}{{20}{1980}{{Chomsky}}{{}}}
\bibcite{christiansen2012similar}{{21}{2012}{{Christiansen et~al.}}{{Christiansen, Conway, and Onnis}}}
\bibcite{collins2003head}{{22}{2003}{{Collins}}{{}}}
\bibcite{collobert2008unified}{{23}{2008}{{Collobert and Weston}}{{}}}
\bibcite{collobert2011natural}{{24}{2011}{{Collobert et~al.}}{{Collobert, Weston, Bottou, Karlen, Kavukcuoglu, and Kuksa}}}
\bibcite{conway2008neurocognitive}{{25}{2008}{{Conway and Pisoni}}{{}}}
\bibcite{cross2016span}{{26}{2016}{{Cross and Huang}}{{}}}
\bibcite{dozat2016deep}{{27}{2016}{{Dozat and Manning}}{{}}}
\bibcite{klein2015crf}{{28}{2015}{{Durrett and Klein}}{{}}}
\bibcite{dyer2016rnng}{{29}{2016}{{Dyer et~al.}}{{Dyer, Kuncoro, Ballesteros, and Smith}}}
\bibcite{eisner2016backprop}{{30}{2016}{{Eisner}}{{}}}
\bibcite{emami2005neural}{{31}{2005}{{Emami and Jelinek}}{{}}}
\bibcite{enguehard2017multitask}{{32}{2017}{{Enguehard et~al.}}{{Enguehard, Goldberg, and Linzen}}}
\bibcite{everaert2015structures}{{33}{2015}{{Everaert et~al.}}{{Everaert, Huybregts, Chomsky, Berwick, and Bolhuis}}}
\bibcite{finkel2008crf}{{34}{2008}{{Finkel et~al.}}{{Finkel, Kleeman, and Manning}}}
\bibcite{frank2012hierarchical}{{35}{2012}{{Frank et~al.}}{{Frank, Bod, and Christiansen}}}
\bibcite{klein2018reinforce}{{36}{2018}{{Fried and Klein}}{{}}}
\bibcite{fu2006gradient}{{37}{2006}{{Fu}}{{}}}
\bibcite{stern2018analyis}{{38}{2018}{{Gaddy et~al.}}{{Gaddy, Stern, and Klein}}}
\bibcite{gallo1993directed}{{39}{1993}{{Gallo et~al.}}{{Gallo, Longo, Pallottino, and Nguyen}}}
\bibcite{giannakidou2011npi}{{40}{2011}{{Giannakidou}}{{}}}
\bibcite{gillespie2011hierarchy}{{41}{2011}{{Gillespie and Pearlmutter}}{{}}}
\bibcite{gillespie2013against}{{42}{2013}{{Gillespie and Pearlmutter}}{{}}}
\bibcite{glorot2010understanding}{{43}{2010}{{Glorot and Bengio}}{{}}}
\bibcite{goldberg2013dynamic}{{44}{2013}{{Goldberg and Nivre}}{{}}}
\bibcite{goodman1999semiring}{{45}{1999}{{Goodman}}{{}}}
\bibcite{gulordava2018colorless}{{46}{2018}{{Gulordava et~al.}}{{Gulordava, Bojanowski, Grave, Linzen, and Baroni}}}
\bibcite{hale2001earley}{{47}{2001}{{Hale}}{{}}}
\bibcite{hale2018beam}{{48}{2018}{{Hale et~al.}}{{Hale, Dyer, Kuncoro, and Brennan}}}
\bibcite{hall2014less}{{49}{2014}{{Hall et~al.}}{{Hall, Durrett, and Klein}}}
\bibcite{he2012imitation}{{50}{2012}{{He et~al.}}{{He, Eisner, and Daume}}}
\bibcite{hochreiter1997long}{{51}{1997}{{Hochreiter and Schmidhuber}}{{}}}
\bibcite{hockenmaier2007ccgbank}{{52}{2007}{{Hockenmaier and Steedman}}{{}}}
\bibcite{huddleston2002grammar}{{53}{2002}{{Huddleston and Pullum}}{{}}}
\bibcite{hudson2010introduction}{{54}{2010}{{Hudson}}{{}}}
\bibcite{jelinek1997information}{{55}{1997}{{Jelinek}}{{}}}
\bibcite{jozefowicz2016exploring}{{56}{2016}{{Jozefowicz et~al.}}{{Jozefowicz, Vinyals, Schuster, Shazeer, and Wu}}}
\bibcite{kalchbrenner2014convolutional}{{57}{2014}{{Kalchbrenner et~al.}}{{Kalchbrenner, Grefenstette, and Blunsom}}}
\bibcite{kim2017structured}{{58}{2017}{{Kim et~al.}}{{Kim, Denton, Hoang, and Rush}}}
\bibcite{kingma2014adam}{{59}{2014}{{Kingma and Ba}}{{}}}
\bibcite{kitaev2018attentive}{{60}{2018}{{Kitaev and Klein}}{{}}}
\bibcite{klein2003accurate}{{61}{2003}{{Klein and Manning}}{{}}}
\bibcite{klein2004parsing}{{62}{2004}{{Klein and Manning}}{{}}}
\bibcite{kneser1995improved}{{63}{1995}{{Kneser and Ney}}{{}}}
\bibcite{kuncoro2017syntax}{{64}{2017}{{Kuncoro et~al.}}{{Kuncoro, Ballesteros, Kong, Dyer, Neubig, and Smith}}}
\bibcite{kuncoro2018learn}{{65}{2018}{{Kuncoro et~al.}}{{Kuncoro, Dyer, Hale, Yogatama, Clark, and Blunsom}}}
\bibcite{lafferty2001crf}{{66}{2001}{{Lafferty et~al.}}{{Lafferty, McCallum, and Pereira}}}
\bibcite{levy2008expectation}{{67}{2008}{{Levy}}{{}}}
\bibcite{eisner2009semirings}{{68}{2009}{{Li and Eisner}}{{}}}
\bibcite{linzen2016syntax}{{69}{2016}{{Linzen et~al.}}{{Linzen, Dupoux, and Goldberg}}}
\bibcite{marcus1994annotating}{{70}{1994}{{Marcus et~al.}}{{Marcus, Kim, Marcinkiewicz, MacIntyre, Bies, Ferguson, Katz, and Schasberger}}}
\bibcite{marcus1993penn}{{71}{1993}{{Marcus et~al.}}{{Marcus, Marcinkiewicz, and Santorini}}}
\bibcite{linzen2018targeted}{{72}{2018}{{Marvin and Linzen}}{{}}}
\bibcite{mccoy2018revisiting}{{73}{2018}{{McCoy et~al.}}{{McCoy, Linzen, and Frank}}}
\bibcite{melis2017state}{{74}{2017}{{Melis et~al.}}{{Melis, Dyer, and Blunsom}}}
\bibcite{merity2016pointer}{{75}{2016}{{Merity et~al.}}{{Merity, Xiong, Bradbury, and Socher}}}
\bibcite{miao2016discrete}{{76}{2016}{{Miao and Blunsom}}{{}}}
\bibcite{mikolov2010recurrent}{{77}{2010}{{Mikolov et~al.}}{{Mikolov, Karafi{\'a}t, Burget, {\v {C}}ernock{\`y}, and Khudanpur}}}
\bibcite{mnih2014nvil}{{78}{2014}{{Mnih and Gregor}}{{}}}
\bibcite{neubig2017dynet}{{79}{2017{a}}{{Neubig et~al.}}{{Neubig, Dyer, Goldberg, Matthews, Ammar, Anastasopoulos, Ballesteros, Chiang, Clothiaux, Cohn, et~al.}}}
\bibcite{neubig2017fly}{{80}{2017{b}}{{Neubig et~al.}}{{Neubig, Goldberg, and Dyer}}}
\bibcite{nivre2005dependency}{{81}{2005}{{Nivre}}{{}}}
\bibcite{paisley2012viss}{{82}{2012}{{Paisley et~al.}}{{Paisley, Blei, and Jordan}}}
\bibcite{pauls2012treelets}{{83}{2012}{{Pauls and Klein}}{{}}}
\bibcite{peters2018elmo}{{84}{2018}{{Peters et~al.}}{{Peters, Neumann, Iyyer, Gardner, Clark, Lee, and Zettlemoyer}}}
\bibcite{petrov2006learning}{{85}{2006}{{Petrov et~al.}}{{Petrov, Barrett, Thibaux, and Klein}}}
\bibcite{ranganath2014black}{{86}{2014}{{Ranganath et~al.}}{{Ranganath, Gerrish, and Blei}}}
\bibcite{rennie2017argmax}{{87}{2017}{{Rennie et~al.}}{{Rennie, Marcheret, Mroueh, Ross, and Goel}}}
\bibcite{roark2001probabilistic}{{88}{2001}{{Roark}}{{}}}
\bibcite{rosenfeld1996loglinear}{{89}{1996}{{Rosenfeld}}{{}}}
\bibcite{ross2006simulation}{{90}{2006}{{Ross}}{{}}}
\bibcite{schulman2015gradient}{{91}{2015}{{Schulman et~al.}}{{Schulman, Heess, Weber, and Abbeel}}}
\bibcite{sekine1997evalb}{{92}{1997}{{Sekine and Collins}}{{}}}
\bibcite{sennrich2017grammatical}{{93}{2017}{{Sennrich}}{{}}}
\bibcite{smith2012adversarial}{{94}{2012}{{Smith}}{{}}}
\bibcite{goldberg2016multitask}{{95}{2016}{{S{\o }gaard and Goldberg}}{{}}}
\bibcite{stern2017minimal}{{96}{2017{a}}{{Stern et~al.}}{{Stern, Andreas, and Klein}}}
\bibcite{stern2017beam}{{97}{2017{b}}{{Stern et~al.}}{{Stern, Fried, and Klein}}}
\bibcite{swayamdipta2018scaffold}{{98}{2018}{{Swayamdipta et~al.}}{{Swayamdipta, Thomson, Lee, Zettlemoyer, Dyer, and Smith}}}
\bibcite{tesniere1959elements}{{99}{1959}{{Tesni{\`e}re}}{{}}}
\bibcite{titov2007generative}{{100}{2007}{{Titov and Henderson}}{{}}}
\bibcite{tran2018recurrent}{{101}{2018}{{Tran et~al.}}{{Tran, Bisazza, and Monz}}}
\bibcite{vaswani2017attention}{{102}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{vlachos2012imitation}{{103}{2013}{{Vlachos}}{{}}}
\bibcite{warstadt2018acceptability}{{104}{2018}{{Warstadt et~al.}}{{Warstadt, Singh, and Bowman}}}
\bibcite{williams1992reinforce}{{105}{1992}{{Williams}}{{}}}
\bibcite{wilson2017marginal}{{106}{2017}{{Wilson et~al.}}{{Wilson, Roelofs, Stern, Srebro, and Recht}}}
\bibcite{xiang2009illusory}{{107}{2009}{{Xiang et~al.}}{{Xiang, Dillon, and Phillips}}}
\bibcite{yin2018structvae}{{108}{2018}{{Yin et~al.}}{{Yin, Zhou, He, and Neubig}}}
\bibcite{zaremba2014recurrent}{{109}{2014}{{Zaremba et~al.}}{{Zaremba, Sutskever, and Vinyals}}}
\bibcite{zhang2016multitask}{{110}{2016}{{Zhang and Weiss}}{{}}}
\bibcite{zweig2011microsoft}{{111}{2011}{{Zweig and Burges}}{{}}}
\global\csname @altsecnumformattrue\endcsname
\global\@namedef{scr@dte@chapter@lastmaxnumwidth}{16.23872pt}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{23.84888pt}
\global\@namedef{scr@dte@subsection@lastmaxnumwidth}{32.06136pt}
