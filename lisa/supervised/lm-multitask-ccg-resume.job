#!/bin/bash
#SBATCH -N 1
#SBATCH -p normal
#SBATCH -J lm-multitask-ccg-resume
#SBATCH -o lisa/out/lm-multitask-ccg-resume.out
#SBATCH -t 5-00:00:00

PATHS=$(ls ${HOME}/thesis/models | grep '^lm-multitask-ccg_')

# send an e-mail when the job starts
echo "Job $SLURM_JOB_NAME started at `date` for models in $PATHS" | mail $USER -s "Started job $SLURM_JOB_NAME"

# write sterr and stout of each experiment here
OUTPUT_DIR=${HOME}/thesis/lisa/out/${SLURM_JOB_NAME}
mkdir -p ${OUTPUT_DIR}

# always run from the main directory
cd ${HOME}/thesis

source lisa/lisa-cpu.sh

# create supervised vocab
python src/main.py build @src/configs/vocab/supervised.txt

for path in $PATHS; do
  seed=$(cat models/${path}/log/args.txt | grep numpy_seed | cut -c14-)
  lisa/train.sh ${seed} ${OUTPUT_DIR} \
    --dynet-autobatch 1 \
    --dynet-mem 2500 \
    --model-path-base models/lm-multitask-ccg  \
    --max-time $((5 * 23 * 3600)) \
    --max-epochs 150 \
    --resume models/${path} \
    @src/configs/vocab/supervised.txt \
    @src/configs/data/supervised-ccg.txt \
    @src/configs/model/lm-multitask-ccg.txt \
    @src/configs/training/sgd.txt \
    &
done

# this waits until all sub-jobs finish
wait

echo "Jobs finished"
echo "Job $SLURM_JOB_NAME ended at `date`" | mail $USER -s "Ended job $SLURM_JOB_NAME"

sleep 300
