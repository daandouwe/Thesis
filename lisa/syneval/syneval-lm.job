#!/bin/bash
#SBATCH -N 1
#SBATCH -p normal
#SBATCH -J syneval-lm
#SBATCH -o lisa/out/syneval-lm.out
#SBATCH -t 0-24:00:00

# as not to tred on each other's toes
export MKL_NUM_THREADS=1

# gather all lm paths to be evaluated
PATHS=$(ls ${HOME}/thesis/models | grep '^lm_dev*')

# send an e-mail when the job starts
echo "Job $SLURM_JOB_NAME started at `date` for the models $PATHS" | mail $USER -s "Started job $SLURM_JOB_NAME"

# write sterr and stout of each experiment here
OUTPUT_DIR=${HOME}/thesis/lisa/out/${SLURM_JOB_NAME}
mkdir -p ${OUTPUT_DIR}

# always run from the main directory
cd ${HOME}/thesis

source lisa/lisa-cpu.sh

# # regular syneval
# for path in $PATHS; do
#   python src/main.py syneval \
#       --dynet-autobatch 1 \
#       --dynet-mem 2500 \
#       --model-type rnn-lm \
# 	    --checkpoint models/${path} \
# 	    --indir data/syneval/data/converted \
#       &
# done

# capitalize first letter
for path in $PATHS; do
  python src/main.py syneval \
      --dynet-autobatch 1 \
      --dynet-mem 2500 \
      --model-type rnn-lm \
	    --checkpoint models/${path} \
	    --indir data/syneval/data/converted \
      --capitalize \
      &
done

# this waits until all sub-jobs finish
wait

echo "Jobs finished"
echo "Job $SLURM_JOB_NAME ended at `date`" | mail $USER -s "Ended job $SLURM_JOB_NAME"

sleep 300
